import ccxt
import numpy as np
import pandas as pd
import requests
import threading
import yfinance as yf
from tradingview_ta import TA_Handler, Interval
import json
import os
from pathlib import Path
from datetime import datetime, timedelta
import time
import logging
import warnings
from dotenv import load_dotenv
import ta  # Thay th·∫ø TA-Lib v·ªõi th∆∞ vi·ªán ta

# Suppress ML warnings
# The warning "No further splits with positive gain" is not an error - it means the model
# has reached its maximum potential with the current data and cannot find more useful splits.
# This is normal behavior and doesn't affect model performance.
warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')
warnings.filterwarnings('ignore', message='.*No further splits with positive gain.*')
warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')
warnings.filterwarnings('ignore', message='.*ConvergenceWarning.*')

# Machine Learning imports
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.feature_selection import SelectKBest, f_classif
import xgboost as xgb
import lightgbm as lgb
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D
from tensorflow.keras.optimizers import Adam
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

# Load environment variables
load_dotenv()

# Thi·∫øt l·∫≠p logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Kh·ªüi t·∫°o k·∫øt n·ªëi v·ªõi Binance mainnet (spot)
exchange = ccxt.binance({
    'enableRateLimit': True,
    'options': {
        'defaultType': 'spot',
        'adjustForTimeDifference': True,
    }
})

# Kh·ªüi t·∫°o k·∫øt n·ªëi v·ªõi Exness cho h√†ng h√≥a (ƒë√£ lo·∫°i b·ªè)
exness_exchange = None

# C·∫•u h√¨nh
# Ch·ªâ ph√¢n t√≠ch crypto; t·∫°m th·ªùi b·ªè v√†ng v√† d·∫ßu do ngu·ªìn d·ªØ li·ªáu kh√¥ng ·ªïn ƒë·ªãnh
SYMBOLS = ['BTC/USDT', 'ETH/USDT']  # B·ªè BNB theo y√™u c·∫ßu c·ªßa user
TIMEFRAMES = ['1h', '2h', '4h', '6h', '8h', '12h', '1d', '3d', '1w']
ML_TIMEFRAMES = ['1h', '2h', '4h', '6h', '8h', '12h', '1d']  # Timeframes cho ML training
CANDLE_LIMIT = 200
SIGNAL_THRESHOLD = 0.6 # Gi·∫£m xu·ªëng 40% ƒë·ªÉ d·ªÖ c√≥ t√≠n hi·ªáu h∆°n
RETRY_ATTEMPTS = 2

# C·∫•u h√¨nh Telegram
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "7496162935:AAGncIsO4q18cOWRGpK0vYb_5zWxYNEgWKQ")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "1866335373")
TELEGRAM_REPORT_INTERVAL = 7200  # 2 ti·∫øng = 7200 gi√¢y

# C·∫•u h√¨nh cho h·ªá th·ªëng theo d√µi d·ª± ƒëo√°n
PREDICTION_DATA_DIR = "prediction_data"
PREDICTION_HISTORY_FILE = "prediction_history.json"
PREDICTION_ACCURACY_FILE = "prediction_accuracy.json"
PREDICTION_UPDATE_INTERVAL = 3600  # C·∫≠p nh·∫≠t k·∫øt qu·∫£ th·ª±c t·∫ø m·ªói gi·ªù
PREDICTION_RETENTION_DAYS = 30  # Gi·ªØ d·ªØ li·ªáu d·ª± ƒëo√°n trong 30 ng√†y

# C·∫•u h√¨nh Machine Learning
ML_MODELS_DIR = "ml_models"
ML_DATA_DIR = "ml_data"
ML_FEATURES_FILE = "ml_features.json"
ML_PERFORMANCE_FILE = "ml_performance.json"
ML_UPDATE_INTERVAL = 86400  # C·∫≠p nh·∫≠t m√¥ h√¨nh ML m·ªói 24 gi·ªù
ML_MIN_SAMPLES = 500  # Gi·∫£m xu·ªëng 500 ƒë·ªÉ d·ªÖ train h∆°n
ML_CONFIDENCE_THRESHOLD = 0.7  # Ng∆∞·ª°ng tin c·∫≠y t·ªëi thi·ªÉu cho d·ª± ƒëo√°n ML
ML_HISTORICAL_CANDLES = 5000  # S·ªë l∆∞·ª£ng candles l·ªãch s·ª≠ ƒë·ªÉ train ML

# C·∫•u h√¨nh ph√¢n t√≠ch h·ªôi t·ª• (Convergence Analysis)
CONVERGENCE_ANALYSIS_ENABLED = True
CONVERGENCE_LOOKBACK_PERIODS = [5, 10, 20, 50]  # C√°c kho·∫£ng th·ªùi gian ƒë·ªÉ ph√¢n t√≠ch h·ªôi t·ª•
CONVERGENCE_THRESHOLD = 0.8  # Ng∆∞·ª°ng h·ªôi t·ª• (0-1)
CONVERGENCE_WEIGHT = 0.3  # Tr·ªçng s·ªë cho t√≠n hi·ªáu h·ªôi t·ª• trong consensus

def get_usdt_symbols():
    """Tr·∫£ v·ªÅ danh s√°ch c·∫∑p giao d·ªãch c·ªë ƒë·ªãnh bao g·ªìm crypto, v√†ng v√† d·∫ßu"""
    return SYMBOLS

def ensure_prediction_data_dir():
    """ƒê·∫£m b·∫£o th∆∞ m·ª•c d·ªØ li·ªáu d·ª± ƒëo√°n t·ªìn t·∫°i"""
    Path(PREDICTION_DATA_DIR).mkdir(exist_ok=True)

def ensure_ml_directories():
    """ƒê·∫£m b·∫£o c√°c th∆∞ m·ª•c ML t·ªìn t·∫°i"""
    Path(ML_MODELS_DIR).mkdir(exist_ok=True)
    Path(ML_DATA_DIR).mkdir(exist_ok=True)

def create_ml_features(data, symbol, timeframe):
    """T·∫°o features cho Machine Learning t·ª´ d·ªØ li·ªáu OHLCV"""
    try:
        df = pd.DataFrame({
            'open': data['open'],
            'high': data['high'],
            'low': data['low'],
            'close': data['close'],
            'volume': data['volume']
        })
        
        # Technical Indicators
        df['rsi'] = ta.momentum.rsi(df['close'], window=14)
        df['macd'] = ta.trend.macd(df['close'])
        df['macd_signal'] = ta.trend.macd_signal(df['close'])
        df['bb_upper'] = ta.volatility.bollinger_hband(df['close'])
        df['bb_lower'] = ta.volatility.bollinger_lband(df['close'])
        df['bb_middle'] = ta.volatility.bollinger_mavg(df['close'])
        df['ema_20'] = ta.trend.ema_indicator(df['close'], window=20)
        df['ema_50'] = ta.trend.ema_indicator(df['close'], window=50)
        df['sma_20'] = ta.trend.sma_indicator(df['close'], window=20)
        df['sma_50'] = ta.trend.sma_indicator(df['close'], window=50)
        df['stoch_k'] = ta.momentum.stoch(df['high'], df['low'], df['close'])
        df['stoch_d'] = ta.momentum.stoch_signal(df['high'], df['low'], df['close'])
        df['adx'] = ta.trend.adx(df['high'], df['low'], df['close'])
        df['atr'] = ta.volatility.average_true_range(df['high'], df['low'], df['close'])
        df['obv'] = ta.volume.on_balance_volume(df['close'], df['volume'])
        
        # Price-based features
        df['price_change'] = df['close'].pct_change()
        df['high_low_ratio'] = df['high'] / df['low']
        df['close_open_ratio'] = df['close'] / df['open']
        df['volume_price_ratio'] = df['volume'] / df['close']
        
        # Moving averages
        df['ma_ratio_20_50'] = df['sma_20'] / df['sma_50']
        df['ema_ratio_20_50'] = df['ema_20'] / df['ema_50']
        
        # Bollinger Bands features
        df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])
        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']
        
        # RSI features
        df['rsi_oversold'] = (df['rsi'] < 30).astype(int)
        df['rsi_overbought'] = (df['rsi'] > 70).astype(int)
        
        # MACD features
        df['macd_cross'] = (df['macd'] > df['macd_signal']).astype(int)
        df['macd_histogram'] = df['macd'] - df['macd_signal']
        
        # Volume features
        df['volume_ma'] = df['volume'].rolling(window=20).mean()
        df['volume_ratio'] = df['volume'] / df['volume_ma']
        
        # Momentum features
        df['momentum'] = df['close'] - df['close'].shift(5)
        df['rate_of_change'] = df['close'].pct_change(5)
        
        # Volatility features
        df['volatility'] = df['close'].rolling(window=20).std()
        df['volatility_ratio'] = df['volatility'] / df['close']
        
        # Advanced features
        # Price patterns
        df['hammer'] = ((df['high'] - df['low']) > 3 * (df['open'] - df['close'])) & \
                      ((df['close'] - df['low']) / (0.001 + df['high'] - df['low']) > 0.6)
        df['doji'] = abs(df['open'] - df['close']) <= (df['high'] - df['low']) * 0.1
        
        # Support/Resistance levels
        df['support_level'] = df['low'].rolling(window=20).min()
        df['resistance_level'] = df['high'].rolling(window=20).max()
        df['support_distance'] = (df['close'] - df['support_level']) / df['close']
        df['resistance_distance'] = (df['resistance_level'] - df['close']) / df['close']
        
        # Volume analysis
        df['volume_sma'] = df['volume'].rolling(window=20).mean()
        df['volume_std'] = df['volume'].rolling(window=20).std()
        df['volume_z_score'] = (df['volume'] - df['volume_sma']) / (df['volume_std'] + 0.001)
        
        # Price momentum indicators
        df['price_acceleration'] = df['price_change'].diff()
        df['volume_price_trend'] = df['volume'] * df['price_change']
        
        # Market structure
        df['higher_high'] = (df['high'] > df['high'].shift(1)).astype(int)
        df['lower_low'] = (df['low'] < df['low'].shift(1)).astype(int)
        df['trend_strength'] = df['higher_high'] - df['lower_low']
        
        # Target variable (next period's direction)
        df['target'] = np.where(df['close'].shift(-1) > df['close'], 1, 0)
        
        # Remove NaN values
        df = df.dropna()
        
        # Feature selection (35+ features)
        feature_columns = [
            # Technical indicators
            'rsi', 'macd', 'macd_signal', 'bb_position', 'bb_width',
            'ema_ratio_20_50', 'ma_ratio_20_50', 'stoch_k', 'stoch_d',
            'adx', 'atr', 'obv',
            
            # Price features
            'price_change', 'high_low_ratio', 'close_open_ratio',
            'rsi_oversold', 'rsi_overbought', 'macd_cross', 'macd_histogram',
            'momentum', 'rate_of_change', 'volatility_ratio',
            
            # Volume features
            'volume_ratio', 'volume_z_score', 'volume_price_trend',
            
            # Support/Resistance
            'support_distance', 'resistance_distance',
            
            # Market structure
            'trend_strength', 'price_acceleration',
            
            # Price patterns
            'hammer', 'doji'
        ]
        
        X = df[feature_columns]
        y = df['target']
        
        return X, y, feature_columns
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi t·∫°o ML features cho {symbol}: {e}")
        return None, None, None

def train_ml_models(symbol, timeframe):
    """Train c√°c m√¥ h√¨nh Machine Learning v·ªõi d·ªØ li·ªáu l·ªãch s·ª≠"""
    try:
        ensure_ml_directories()
        
        # L·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ (5000 candles)
        data = load_or_fetch_historical_data(symbol, timeframe)
        if data is None:
            logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol} ({timeframe})")
            return None
            
        logger.info(f"üìä D·ªØ li·ªáu {symbol} ({timeframe}): {len(data['close'])} candles")
        
        if len(data['close']) < ML_MIN_SAMPLES:
            logger.warning(f"‚ö†Ô∏è Kh√¥ng ƒë·ªß d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·ªÉ train ML cho {symbol} ({timeframe}): {len(data['close'])} < {ML_MIN_SAMPLES}")
            return None
        
        # T·∫°o features
        X, y, feature_columns = create_ml_features(data, symbol, timeframe)
        if X is None:
            logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o features cho {symbol} ({timeframe})")
            return None
            
        logger.info(f"üîß Features {symbol} ({timeframe}): {len(X)} samples, {len(feature_columns)} features")
        
        if len(X) < ML_MIN_SAMPLES:
            logger.warning(f"‚ö†Ô∏è Kh√¥ng ƒë·ªß features ƒë·ªÉ train ML cho {symbol} ({timeframe}): {len(X)} < {ML_MIN_SAMPLES}")
            return None
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        logger.info(f"üìà Training set: {len(X_train)} samples, Test set: {len(X_test)} samples")
        
        # Scale features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Initialize models
        models = {
            'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),
            'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
            'xgboost': xgb.XGBClassifier(n_estimators=100, random_state=42),
            'lightgbm': lgb.LGBMClassifier(
                n_estimators=100, 
                random_state=42,
                verbose=-1,  # Suppress LightGBM output
                silent=True,  # Suppress LightGBM warnings
                min_child_samples=10,  # Minimum samples per leaf to avoid overfitting
                min_split_gain=0.0  # Allow splits with zero gain
            ),
            'logistic_regression': LogisticRegression(random_state=42),
            'svm': SVC(probability=True, random_state=42)
        }
        
        trained_models = {}
        model_performance = {}
        
        # Train each model
        for name, model in models.items():
            try:
                logger.info(f"üîÑ Training {name} cho {symbol} ({timeframe})...")
                
                # Suppress warnings during training
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    
                    if name in ['svm', 'logistic_regression']:
                        model.fit(X_train_scaled, y_train)
                        y_pred = model.predict(X_test_scaled)
                        y_proba = model.predict_proba(X_test_scaled)[:, 1]
                    else:
                        model.fit(X_train, y_train)
                        y_pred = model.predict(X_test)
                        y_proba = model.predict_proba(X_test)[:, 1]
                
                # Calculate performance
                accuracy = accuracy_score(y_test, y_pred)
                cv_scores = cross_val_score(model, X_train, y_train, cv=5)
                
                model_performance[name] = {
                    'accuracy': accuracy,
                    'cv_mean': cv_scores.mean(),
                    'cv_std': cv_scores.std()
                }
                
                trained_models[name] = {
                    'model': model,
                    'scaler': scaler if name in ['svm', 'logistic_regression'] else None,
                    'feature_columns': feature_columns,
                    'performance': model_performance[name]
                }
                
                logger.info(f"‚úÖ {name} trained - Accuracy: {accuracy:.3f}, CV: {cv_scores.mean():.3f}¬±{cv_scores.std():.3f}")
                
            except Exception as e:
                logger.error(f"‚ùå L·ªói khi train {name} cho {symbol}: {e}")
                continue
        
        # Save models
        safe_symbol = symbol.replace('/', '_')
        for name, model_data in trained_models.items():
            model_file = os.path.join(ML_MODELS_DIR, f"{safe_symbol}_{timeframe}_{name}.joblib")
            joblib.dump(model_data, model_file)
        
        # Save performance
        performance_file = os.path.join(ML_DATA_DIR, f"{safe_symbol}_{timeframe}_performance.json")
        with open(performance_file, 'w') as f:
            json.dump(model_performance, f, indent=2)
        
        logger.info(f"‚úÖ ƒê√£ train v√† l∆∞u {len(trained_models)} m√¥ h√¨nh ML cho {symbol} ({timeframe})")
        return trained_models
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi train ML models cho {symbol}: {e}")
        return None

def predict_with_ml(symbol, timeframe, current_data):
    """D·ª± ƒëo√°n s·ª≠ d·ª•ng Machine Learning"""
    try:
        ensure_ml_directories()
        
        # Use safe symbol format (same as in train_ml_models)
        safe_symbol = symbol.replace('/', '_')
        
        # Load best performing model
        performance_file = os.path.join(ML_DATA_DIR, f"{safe_symbol}_{timeframe}_performance.json")
        if not os.path.exists(performance_file):
            logger.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh ML cho {symbol} ({timeframe})")
            return None
        
        with open(performance_file, 'r') as f:
            performance = json.load(f)
        
        # Find best model
        best_model_name = max(performance.keys(), key=lambda x: performance[x]['cv_mean'])
        best_model_file = os.path.join(ML_MODELS_DIR, f"{safe_symbol}_{timeframe}_{best_model_name}.joblib")
        
        if not os.path.exists(best_model_file):
            logger.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh {best_model_name} cho {symbol}")
            return None
        
        # Load model
        model_data = joblib.load(best_model_file)
        model = model_data['model']
        scaler = model_data['scaler']
        feature_columns = model_data['feature_columns']
        
        # Create features for current data
        X_current, _, _ = create_ml_features(current_data, symbol, timeframe)
        if X_current is None or X_current.empty:
            return None
        
        # Get latest features
        latest_features = X_current[feature_columns].iloc[-1:].values
        
        # Scale if needed
        if scaler is not None:
            latest_features = scaler.transform(latest_features)
        
        # Make prediction
        prediction_proba = model.predict_proba(latest_features)[0]
        prediction_class = model.predict(latest_features)[0]
        
        # Calculate confidence
        confidence = max(prediction_proba)
        
        # Determine signal
        if prediction_class == 1 and confidence > ML_CONFIDENCE_THRESHOLD:
            signal = 'Long'
        elif prediction_class == 0 and confidence > ML_CONFIDENCE_THRESHOLD:
            signal = 'Short'
        else:
            signal = 'Hold'
        
        return {
            'signal': signal,
            'confidence': confidence,
            'probability': prediction_proba,
            'model_name': best_model_name,
            'model_performance': performance[best_model_name]
        }
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi d·ª± ƒëo√°n ML cho {symbol}: {e}")
        return None

def analyze_convergence(data, lookback_periods=None):
    """Ph√¢n t√≠ch h·ªôi t·ª• (Convergence Analysis)"""
    if not CONVERGENCE_ANALYSIS_ENABLED:
        return None
    
    if lookback_periods is None:
        lookback_periods = CONVERGENCE_LOOKBACK_PERIODS
    
    try:
        # Convert to pandas Series if it's a numpy array
        close_prices = pd.Series(data['close']) if not isinstance(data['close'], pd.Series) else data['close']
        volume_data = pd.Series(data['volume']) if not isinstance(data['volume'], pd.Series) else data['volume']
        
        convergence_analysis = {
            'overall_convergence': 0.0,
            'period_convergence': {},
            'signals': [],
            'strength': 0.0
        }
        
        for period in lookback_periods:
            if len(close_prices) < period * 2:
                continue
            
            # T√≠nh to√°n c√°c ch·ªâ s·ªë cho period n√†y
            recent_prices = close_prices.iloc[-period:].values
            older_prices = close_prices.iloc[-period*2:-period].values
            
            # 1. Price Convergence
            recent_std = np.std(recent_prices)
            older_std = np.std(older_prices)
            price_convergence = 1 - (recent_std / older_std) if older_std > 0 else 0
            
            # 2. Volume Convergence
            recent_volume = volume_data.iloc[-period:].values
            older_volume = volume_data.iloc[-period*2:-period].values
            recent_vol_std = np.std(recent_volume)
            older_vol_std = np.std(older_volume)
            volume_convergence = 1 - (recent_vol_std / older_vol_std) if older_vol_std > 0 else 0
            
            # 3. Momentum Convergence
            recent_momentum = np.diff(recent_prices)
            older_momentum = np.diff(older_prices)
            # Remove NaN values
            recent_momentum = recent_momentum[~np.isnan(recent_momentum)]
            older_momentum = older_momentum[~np.isnan(older_momentum)]
            recent_mom_std = np.std(recent_momentum) if len(recent_momentum) > 0 else 0
            older_mom_std = np.std(older_momentum) if len(older_momentum) > 0 else 0
            momentum_convergence = 1 - (recent_mom_std / older_mom_std) if older_mom_std > 0 else 0
            
            # 4. RSI Convergence
            rsi = ta.momentum.rsi(close_prices, window=14)
            recent_rsi = rsi.iloc[-period:].values
            older_rsi = rsi.iloc[-period*2:-period].values
            # Remove NaN values
            recent_rsi = recent_rsi[~np.isnan(recent_rsi)]
            older_rsi = older_rsi[~np.isnan(older_rsi)]
            recent_rsi_std = np.std(recent_rsi) if len(recent_rsi) > 0 else 0
            older_rsi_std = np.std(older_rsi) if len(older_rsi) > 0 else 0
            rsi_convergence = 1 - (recent_rsi_std / older_rsi_std) if older_rsi_std > 0 else 0
            
            # 5. MACD Convergence
            macd = ta.trend.macd(close_prices)
            recent_macd = macd.iloc[-period:].values
            older_macd = macd.iloc[-period*2:-period].values
            # Remove NaN values
            recent_macd = recent_macd[~np.isnan(recent_macd)]
            older_macd = older_macd[~np.isnan(older_macd)]
            recent_macd_std = np.std(recent_macd) if len(recent_macd) > 0 else 0
            older_macd_std = np.std(older_macd) if len(older_macd) > 0 else 0
            macd_convergence = 1 - (recent_macd_std / older_macd_std) if older_macd_std > 0 else 0
            
            # T√≠nh convergence t·ªïng h·ª£p cho period
            period_convergence = np.mean([
                price_convergence, volume_convergence, momentum_convergence,
                rsi_convergence, macd_convergence
            ])
            
            convergence_analysis['period_convergence'][f'{period}_periods'] = {
                'overall': period_convergence,
                'price': price_convergence,
                'volume': volume_convergence,
                'momentum': momentum_convergence,
                'rsi': rsi_convergence,
                'macd': macd_convergence
            }
            
            # T·∫°o t√≠n hi·ªáu d·ª±a tr√™n convergence
            if period_convergence > CONVERGENCE_THRESHOLD:
                # Convergence cao ‚Üí c√≥ th·ªÉ s·∫Øp breakout
                current_price = close_prices[-1]
                sma_20 = ta.trend.sma_indicator(close_prices, window=20).iloc[-1]
                
                if current_price > sma_20:
                    signal = 'Long'
                else:
                    signal = 'Short'
                
                convergence_analysis['signals'].append({
                    'period': period,
                    'signal': signal,
                    'strength': period_convergence,
                    'type': 'convergence_breakout'
                })
        
        # T√≠nh convergence t·ªïng th·ªÉ
        if convergence_analysis['period_convergence']:
            overall_convergence = np.mean([
                data['overall'] for data in convergence_analysis['period_convergence'].values()
            ])
            convergence_analysis['overall_convergence'] = overall_convergence
            convergence_analysis['strength'] = overall_convergence
        
        return convergence_analysis
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi ph√¢n t√≠ch convergence: {e}")
        return None

def save_prediction(symbol, timeframe, prediction_data, current_price):
    """L∆∞u d·ª± ƒëo√°n m·ªõi v√†o h·ªá th·ªëng"""
    try:
        ensure_prediction_data_dir()
        
        prediction = {
            'id': f"{symbol}_{timeframe}_{int(time.time())}",
            'symbol': symbol,
            'timeframe': timeframe,
            'timestamp': datetime.now().isoformat(),
            'current_price': current_price,
            'prediction': {
                'trend': prediction_data.get('trend', 'neutral'),
                'signal': prediction_data.get('signal', 'Hold'),
                'confidence': prediction_data.get('confidence', 0),
                'entry_price': prediction_data.get('entry_points', {}).get('entry_price', current_price),
                'stop_loss': prediction_data.get('entry_points', {}).get('stop_loss', 0),
                'take_profit': prediction_data.get('entry_points', {}).get('take_profit', 0),
                'risk_reward_ratio': prediction_data.get('entry_points', {}).get('risk_reward_ratio', 0),
                'analysis_summary': prediction_data.get('analysis_summary', ''),
                'technical_signals': prediction_data.get('technical_signals', {}),
                'commodity_signals': prediction_data.get('commodity_signals', {}),
                'smc_signals': prediction_data.get('smc_signals', {}),
                'price_action_signals': prediction_data.get('price_action_signals', {})
            },
            'actual_result': None,
            'accuracy': None,
            'status': 'pending'
        }
        
        # ƒê·ªçc d·ªØ li·ªáu hi·ªán t·∫°i
        history_file = os.path.join(PREDICTION_DATA_DIR, PREDICTION_HISTORY_FILE)
        if os.path.exists(history_file):
            with open(history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
        else:
            history = []
        
        # Th√™m d·ª± ƒëo√°n m·ªõi
        history.append(prediction)
        
        # L∆∞u l·∫°i
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        
        logger.info(f"‚úÖ ƒê√£ l∆∞u d·ª± ƒëo√°n cho {symbol} ({timeframe}): {prediction['prediction']['signal']}")
        return prediction['id']
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi l∆∞u d·ª± ƒëo√°n: {e}")
        return None

def update_prediction_results():
    """C·∫≠p nh·∫≠t k·∫øt qu·∫£ th·ª±c t·∫ø cho c√°c d·ª± ƒëo√°n ƒëang ch·ªù"""
    try:
        ensure_prediction_data_dir()
        history_file = os.path.join(PREDICTION_DATA_DIR, PREDICTION_HISTORY_FILE)
        
        if not os.path.exists(history_file):
            return
        
        with open(history_file, 'r', encoding='utf-8') as f:
            history = json.load(f)
        
        updated = False
        current_time = datetime.now()
        
        for prediction in history:
            if prediction['status'] != 'pending':
                continue
            
            # Ki·ªÉm tra xem ƒë√£ ƒë·∫øn l√∫c c·∫≠p nh·∫≠t ch∆∞a (d·ª±a tr√™n timeframe)
            prediction_time = datetime.fromisoformat(prediction['timestamp'])
            timeframe = prediction['timeframe']
            
            # T√≠nh th·ªùi gian c·∫ßn thi·∫øt ƒë·ªÉ ƒë√°nh gi√° d·ª± ƒëo√°n
            evaluation_time = get_evaluation_time(timeframe)
            if (current_time - prediction_time).total_seconds() < evaluation_time:
                continue
            
            # L·∫•y gi√° hi·ªán t·∫°i
            current_price = get_current_price_for_prediction(prediction['symbol'])
            if current_price is None:
                continue
            
            # T√≠nh to√°n k·∫øt qu·∫£ th·ª±c t·∫ø
            actual_result = calculate_actual_result(
                prediction['prediction'],
                prediction['current_price'],
                current_price,
                timeframe
            )
            
            # C·∫≠p nh·∫≠t d·ª± ƒëo√°n
            prediction['actual_result'] = actual_result
            prediction['accuracy'] = calculate_prediction_accuracy(
                prediction['prediction'],
                actual_result
            )
            prediction['status'] = 'completed'
            updated = True
            
            logger.info(f"üìä C·∫≠p nh·∫≠t k·∫øt qu·∫£ {prediction['symbol']}: {actual_result['outcome']} (ƒê·ªô ch√≠nh x√°c: {prediction['accuracy']:.1%})")
        
        if updated:
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
            
            # C·∫≠p nh·∫≠t th·ªëng k√™ ƒë·ªô ch√≠nh x√°c
            update_accuracy_statistics()
    
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi c·∫≠p nh·∫≠t k·∫øt qu·∫£ d·ª± ƒëo√°n: {e}")

def get_evaluation_time(timeframe):
    """T√≠nh th·ªùi gian c·∫ßn thi·∫øt ƒë·ªÉ ƒë√°nh gi√° d·ª± ƒëo√°n d·ª±a tr√™n timeframe"""
    timeframe_hours = {
        '1h': 3,    # ƒê√°nh gi√° sau 2 gi·ªù
        '2h': 6,    # ƒê√°nh gi√° sau 4 gi·ªù
        '4h': 12,    # ƒê√°nh gi√° sau 8 gi·ªù
        '6h': 18,   # ƒê√°nh gi√° sau 12 gi·ªù
        '8h': 24,   # ƒê√°nh gi√° sau 16 gi·ªù
        '12h': 36,  # ƒê√°nh gi√° sau 24 gi·ªù
        '1d': 72,   # ƒê√°nh gi√° sau 48 gi·ªù
        '3d': 216,  # ƒê√°nh gi√° sau 6 ng√†y
        '1w': 672   # ƒê√°nh gi√° sau 14 ng√†y
    }
    return timeframe_hours.get(timeframe, 24) * 3600  # Chuy·ªÉn sang gi√¢y

def get_current_price_for_prediction(symbol):
    """L·∫•y gi√° hi·ªán t·∫°i cho vi·ªác c·∫≠p nh·∫≠t d·ª± ƒëo√°n"""
    try:
        ticker = exchange.fetch_ticker(symbol)
        return ticker['last']
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi l·∫•y gi√° hi·ªán t·∫°i cho {symbol}: {e}")
        return None

def calculate_actual_result(prediction, initial_price, current_price, timeframe):
    """T√≠nh to√°n k·∫øt qu·∫£ th·ª±c t·∫ø c·ªßa d·ª± ƒëo√°n"""
    price_change = (current_price - initial_price) / initial_price
    price_change_percent = price_change * 100
    
    # L·∫•y th√¥ng tin d·ª± ƒëo√°n
    predicted_trend = prediction.get('trend', 'neutral')
    predicted_signal = prediction.get('signal', 'Hold')
    entry_price = prediction.get('entry_price', initial_price)
    stop_loss = prediction.get('stop_loss', 0)
    take_profit = prediction.get('take_profit', 0)
    
    # X√°c ƒë·ªãnh k·∫øt qu·∫£
    if predicted_signal == 'Long':
        if current_price > entry_price:
            if take_profit > 0 and current_price >= take_profit:
                outcome = 'take_profit_hit'
            else:
                outcome = 'profitable'
        elif stop_loss > 0 and current_price <= stop_loss:
            outcome = 'stop_loss_hit'
        else:
            outcome = 'loss'
    elif predicted_signal == 'Short':
        if current_price < entry_price:
            if take_profit > 0 and current_price <= take_profit:
                outcome = 'take_profit_hit'
            else:
                outcome = 'profitable'
        elif stop_loss > 0 and current_price >= stop_loss:
            outcome = 'stop_loss_hit'
        else:
            outcome = 'loss'
    else:  # Hold
        if abs(price_change) < 0.01:  # Thay ƒë·ªïi < 1%
            outcome = 'correct_hold'
        else:
            outcome = 'missed_opportunity'
    
    return {
        'current_price': current_price,
        'price_change': price_change,
        'price_change_percent': price_change_percent,
        'outcome': outcome,
        'profit_loss': current_price - entry_price if entry_price > 0 else 0,
        'profit_loss_percent': ((current_price - entry_price) / entry_price * 100) if entry_price > 0 else 0
    }

def calculate_prediction_accuracy(prediction, actual_result):
    """T√≠nh to√°n ƒë·ªô ch√≠nh x√°c c·ªßa d·ª± ƒëo√°n"""
    predicted_signal = prediction.get('signal', 'Hold')
    outcome = actual_result.get('outcome', 'unknown')
    
    # ƒê·ªãnh nghƒ©a ƒë·ªô ch√≠nh x√°c
    accuracy_map = {
        'Long': {
            'profitable': 1.0,
            'take_profit_hit': 1.0,
            'stop_loss_hit': 0.0,
            'loss': 0.0
        },
        'Short': {
            'profitable': 1.0,
            'take_profit_hit': 1.0,
            'stop_loss_hit': 0.0,
            'loss': 0.0
        },
        'Hold': {
            'correct_hold': 1.0,
            'missed_opportunity': 0.5
        }
    }
    
    return accuracy_map.get(predicted_signal, {}).get(outcome, 0.0)

def update_accuracy_statistics():
    """C·∫≠p nh·∫≠t th·ªëng k√™ ƒë·ªô ch√≠nh x√°c t·ªïng th·ªÉ"""
    try:
        history_file = os.path.join(PREDICTION_DATA_DIR, PREDICTION_HISTORY_FILE)
        accuracy_file = os.path.join(PREDICTION_DATA_DIR, PREDICTION_ACCURACY_FILE)
        
        if not os.path.exists(history_file):
            return
        
        with open(history_file, 'r', encoding='utf-8') as f:
            history = json.load(f)
        
        # L·ªçc c√°c d·ª± ƒëo√°n ƒë√£ ho√†n th√†nh
        completed_predictions = [p for p in history if p['status'] == 'completed']
        
        if not completed_predictions:
            return
        
        # T√≠nh to√°n th·ªëng k√™
        total_predictions = len(completed_predictions)
        accurate_predictions = len([p for p in completed_predictions if p['accuracy'] >= 0.8])
        overall_accuracy = accurate_predictions / total_predictions if total_predictions > 0 else 0
        
        # Th·ªëng k√™ theo symbol
        symbol_stats = {}
        for prediction in completed_predictions:
            symbol = prediction['symbol']
            if symbol not in symbol_stats:
                symbol_stats[symbol] = {'total': 0, 'accurate': 0, 'accuracy': 0}
            
            symbol_stats[symbol]['total'] += 1
            if prediction['accuracy'] >= 0.8:
                symbol_stats[symbol]['accurate'] += 1
        
        # T√≠nh ƒë·ªô ch√≠nh x√°c cho t·ª´ng symbol
        for symbol in symbol_stats:
            stats = symbol_stats[symbol]
            stats['accuracy'] = stats['accurate'] / stats['total'] if stats['total'] > 0 else 0
        
        # Th·ªëng k√™ theo timeframe
        timeframe_stats = {}
        for prediction in completed_predictions:
            timeframe = prediction['timeframe']
            if timeframe not in timeframe_stats:
                timeframe_stats[timeframe] = {'total': 0, 'accurate': 0, 'accuracy': 0}
            
            timeframe_stats[timeframe]['total'] += 1
            if prediction['accuracy'] >= 0.8:
                timeframe_stats[timeframe]['accurate'] += 1
        
        # T√≠nh ƒë·ªô ch√≠nh x√°c cho t·ª´ng timeframe
        for timeframe in timeframe_stats:
            stats = timeframe_stats[timeframe]
            stats['accuracy'] = stats['accurate'] / stats['total'] if stats['total'] > 0 else 0
        
        # L∆∞u th·ªëng k√™
        accuracy_data = {
            'last_updated': datetime.now().isoformat(),
            'overall': {
                'total_predictions': total_predictions,
                'accurate_predictions': accurate_predictions,
                'accuracy': overall_accuracy
            },
            'by_symbol': symbol_stats,
            'by_timeframe': timeframe_stats
        }
        
        with open(accuracy_file, 'w', encoding='utf-8') as f:
            json.dump(accuracy_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üìà ƒê√£ c·∫≠p nh·∫≠t th·ªëng k√™ ƒë·ªô ch√≠nh x√°c: {overall_accuracy:.1%} ({accurate_predictions}/{total_predictions})")
    
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi c·∫≠p nh·∫≠t th·ªëng k√™ ƒë·ªô ch√≠nh x√°c: {e}")

def get_prediction_accuracy_data():
    """L·∫•y d·ªØ li·ªáu ƒë·ªô ch√≠nh x√°c d·ª± ƒëo√°n"""
    try:
        accuracy_file = os.path.join(PREDICTION_DATA_DIR, PREDICTION_ACCURACY_FILE)
        if os.path.exists(accuracy_file):
            with open(accuracy_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi ƒë·ªçc d·ªØ li·ªáu ƒë·ªô ch√≠nh x√°c: {e}")
        return None

def cleanup_old_predictions():
    """D·ªçn d·∫πp c√°c d·ª± ƒëo√°n c≈©"""
    try:
        history_file = os.path.join(PREDICTION_DATA_DIR, PREDICTION_HISTORY_FILE)
        if not os.path.exists(history_file):
            return
        
        with open(history_file, 'r', encoding='utf-8') as f:
            history = json.load(f)
        
        current_time = datetime.now()
        cutoff_time = current_time.timestamp() - (PREDICTION_RETENTION_DAYS * 24 * 3600)
        
        # L·ªçc b·ªè c√°c d·ª± ƒëo√°n c≈©
        filtered_history = []
        removed_count = 0
        
        for prediction in history:
            prediction_timestamp = datetime.fromisoformat(prediction['timestamp']).timestamp()
            if prediction_timestamp > cutoff_time:
                filtered_history.append(prediction)
            else:
                removed_count += 1
        
        if removed_count > 0:
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(filtered_history, f, ensure_ascii=False, indent=2)
            
            logger.info(f"üßπ ƒê√£ d·ªçn d·∫πp {removed_count} d·ª± ƒëo√°n c≈©")
    
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi d·ªçn d·∫πp d·ª± ƒëo√°n c≈©: {e}")

def adjust_analysis_based_on_accuracy(analysis_result, symbol, timeframe):
    """ƒêi·ªÅu ch·ªânh ph√¢n t√≠ch d·ª±a tr√™n ƒë·ªô ch√≠nh x√°c l·ªãch s·ª≠"""
    try:
        accuracy_data = get_prediction_accuracy_data()
        if not accuracy_data:
            return analysis_result
        
        # L·∫•y ƒë·ªô ch√≠nh x√°c cho symbol v√† timeframe
        symbol_accuracy = accuracy_data.get('by_symbol', {}).get(symbol, {}).get('accuracy', 0.5)
        timeframe_accuracy = accuracy_data.get('by_timeframe', {}).get(timeframe, {}).get('accuracy', 0.5)
        
        # T√≠nh ƒë·ªô ch√≠nh x√°c trung b√¨nh
        avg_accuracy = (symbol_accuracy + timeframe_accuracy) / 2
        
        # ƒêi·ªÅu ch·ªânh confidence d·ª±a tr√™n ƒë·ªô ch√≠nh x√°c
        current_confidence = analysis_result.get('confidence', 0.5)
        
        if avg_accuracy > 0.7:  # ƒê·ªô ch√≠nh x√°c cao
            adjusted_confidence = min(current_confidence * 1.2, 1.0)
            analysis_result['confidence'] = adjusted_confidence
            analysis_result['accuracy_adjustment'] = f"TƒÉng confidence do ƒë·ªô ch√≠nh x√°c cao ({avg_accuracy:.1%})"
        elif avg_accuracy < 0.4:  # ƒê·ªô ch√≠nh x√°c th·∫•p
            adjusted_confidence = max(current_confidence * 0.8, 0.1)
            analysis_result['confidence'] = adjusted_confidence
            analysis_result['accuracy_adjustment'] = f"Gi·∫£m confidence do ƒë·ªô ch√≠nh x√°c th·∫•p ({avg_accuracy:.1%})"
        else:
            analysis_result['accuracy_adjustment'] = f"ƒê·ªô ch√≠nh x√°c trung b√¨nh ({avg_accuracy:.1%})"
        
        # Th√™m th√¥ng tin ƒë·ªô ch√≠nh x√°c v√†o analysis
        analysis_result['historical_accuracy'] = {
            'symbol_accuracy': symbol_accuracy,
            'timeframe_accuracy': timeframe_accuracy,
            'average_accuracy': avg_accuracy
        }
        
        return analysis_result
    
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi ƒëi·ªÅu ch·ªânh ph√¢n t√≠ch: {e}")
        return analysis_result

def send_prediction_accuracy_report():
    """G·ª≠i b√°o c√°o ƒë·ªô ch√≠nh x√°c d·ª± ƒëo√°n qua Telegram"""
    try:
        accuracy_report = format_prediction_accuracy_report()
        if send_telegram_message(accuracy_report):
            logger.info("üìä ƒê√£ g·ª≠i b√°o c√°o ƒë·ªô ch√≠nh x√°c d·ª± ƒëo√°n qua Telegram")
            return True
        else:
            logger.error("‚ùå Kh√¥ng th·ªÉ g·ª≠i b√°o c√°o ƒë·ªô ch√≠nh x√°c d·ª± ƒëo√°n")
            return False
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi g·ª≠i b√°o c√°o ƒë·ªô ch√≠nh x√°c: {e}")
        return False

# ƒê√£ lo·∫°i b·ªè t·∫•t c·∫£ c√°c h√†m li√™n quan ƒë·∫øn h√†ng h√≥a (v√†ng, d·∫ßu)

def fetch_ohlcv(symbol, timeframe, limit):
    """L·∫•y d·ªØ li·ªáu OHLCV cho crypto"""
    for attempt in range(RETRY_ATTEMPTS):
        try:
            # X·ª≠ l√Ω cho crypto
            ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=limit)
            
            if len(ohlcv) < limit * 0.8:
                logger.warning(f"‚ö†Ô∏è D·ªØ li·ªáu OHLCV cho {symbol} ({timeframe}) kh√¥ng ƒë·ªß: {len(ohlcv)}/{limit}")
                return None
                
            return {
                'open': np.array([candle[1] for candle in ohlcv]),
                'high': np.array([candle[2] for candle in ohlcv]),
                'low': np.array([candle[3] for candle in ohlcv]),
                'close': np.array([candle[4] for candle in ohlcv]),
                'volume': np.array([candle[5] for candle in ohlcv])
            }
        except Exception as e:
            error_msg = str(e)
            if "Invalid symbol status" in error_msg or "symbol not found" in error_msg.lower():
                logger.warning(f"‚ö†Ô∏è Symbol {symbol} kh√¥ng kh·∫£ d·ª•ng cho {timeframe}: {error_msg}")
                return None
            elif attempt < RETRY_ATTEMPTS - 1:
                logger.warning(f"‚ö†Ô∏è L·ªói khi l·∫•y d·ªØ li·ªáu OHLCV cho {symbol} ({timeframe}, l·∫ßn {attempt + 1}/{RETRY_ATTEMPTS}): {error_msg}")
                time.sleep(1)
            else:
                logger.error(f"‚ùå Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu OHLCV cho {symbol} ({timeframe}): {error_msg}")
    return None

def calculate_fibonacci_levels(highs, lows):
    """T√≠nh c√°c m·ª©c Fibonacci Retracement"""
    max_price = max(highs[-50:])
    min_price = min(lows[-50:])
    diff = max_price - min_price
    levels = {
        '23.6%': max_price - 0.236 * diff,
        '38.2%': max_price - 0.382 * diff,
        '50%': max_price - 0.5 * diff,
        '61.8%': max_price - 0.618 * diff
    }
    return levels

def find_support_resistance(highs, lows, current_price):
    """T√¨m m·ª©c h·ªó tr·ª£/kh√°ng c·ª± g·∫ßn nh·∫•t"""
    fib_levels = calculate_fibonacci_levels(highs, lows)
    support = min([price for price in fib_levels.values() if price < current_price], default=min(lows[-20:]))
    resistance = max([price for price in fib_levels.values() if price > current_price], default=max(highs[-20:]))
    return support, resistance

def calculate_pivot_points(highs, lows, closes):
    """T√≠nh c√°c m·ª©c Pivot Points (Classic)"""
    high = highs.iloc[-1] if hasattr(highs, 'iloc') else highs[-1]
    low = lows.iloc[-1] if hasattr(lows, 'iloc') else lows[-1]
    close = closes.iloc[-1] if hasattr(closes, 'iloc') else closes[-1]
    pivot = (high + low + close) / 3
    r1 = (2 * pivot) - low
    s1 = (2 * pivot) - high
    r2 = pivot + (high - low)
    s2 = pivot - (high - low)
    r3 = high + 2 * (pivot - low)
    s3 = low - 2 * (high - pivot)
    return {'pivot': pivot, 'r1': r1, 's1': s1, 'r2': r2, 's2': s2, 'r3': r3, 's3': s3}

def calculate_volume_profile(highs, lows, volumes, bins=10):
    """T√≠nh Volume Profile ƒë∆°n gi·∫£n (ph√¢n b·ªë kh·ªëi l∆∞·ª£ng theo m·ª©c gi√°)"""
    # Chuy·ªÉn ƒë·ªïi sang list n·∫øu l√† pandas Series
    highs_list = highs.tolist() if hasattr(highs, 'tolist') else highs
    lows_list = lows.tolist() if hasattr(lows, 'tolist') else lows
    volumes_list = volumes.tolist() if hasattr(volumes, 'tolist') else volumes
    
    price_range = max(highs_list[-50:]) - min(lows_list[-50:])
    bin_size = price_range / bins
    volume_bins = [0] * bins
    for i in range(len(highs_list[-50:])):
        price = (highs_list[-50:][i] + lows_list[-50:][i]) / 2
        bin_index = min(int((price - min(lows_list[-50:])) / bin_size), bins - 1)
        volume_bins[bin_index] += volumes_list[-50:][i]
    max_volume_price = min(lows_list[-50:]) + volume_bins.index(max(volume_bins)) * bin_size
    return max_volume_price

def calculate_vwap(highs, lows, closes, volumes):
    """T√≠nh VWAP (Volume Weighted Average Price)"""
    # Chuy·ªÉn ƒë·ªïi sang numpy array n·∫øu c·∫ßn
    highs_array = highs.values if hasattr(highs, 'values') else np.array(highs)
    lows_array = lows.values if hasattr(lows, 'values') else np.array(lows)
    closes_array = closes.values if hasattr(closes, 'values') else np.array(closes)
    volumes_array = volumes.values if hasattr(volumes, 'values') else np.array(volumes)
    
    typical_prices = (highs_array[-20:] + lows_array[-20:] + closes_array[-20:]) / 3
    vwap = np.sum(typical_prices * volumes_array[-20:]) / np.sum(volumes_array[-20:])
    return vwap

def detect_price_patterns(highs, lows, closes):
    """Ph√°t hi·ªán c√°c m√¥ h√¨nh gi√°"""
    pattern = 'None'
    
    # Chuy·ªÉn ƒë·ªïi sang list n·∫øu l√† pandas Series
    highs_list = highs.tolist() if hasattr(highs, 'tolist') else highs
    lows_list = lows.tolist() if hasattr(lows, 'tolist') else lows
    closes_list = closes.tolist() if hasattr(closes, 'tolist') else closes
    
    # ƒê·ªânh ƒë·∫ßu vai (Head and Shoulders)
    if len(highs_list) >= 7:
        left_shoulder = highs_list[-5] > highs_list[-6] and highs_list[-5] > highs_list[-4]
        head = highs_list[-3] > highs_list[-5] and highs_list[-3] > highs_list[-1]
        right_shoulder = highs_list[-1] > highs_list[-2] and highs_list[-1] < highs_list[-3]
        if left_shoulder and head and right_shoulder:
            pattern = 'Head and Shoulders'
    
    # ƒê·ªânh ƒë√¥i (Double Top)
    elif len(highs_list) >= 5:
        if abs(highs_list[-3] - highs_list[-1]) / highs_list[-3] < 0.01 and highs_list[-3] > highs_list[-2] and highs_list[-1] > highs_list[-2]:
            pattern = 'Double Top'
    
    # C·ªù (Flag)
    elif len(highs_list) >= 10:
        uptrend = all(closes_list[i] > closes_list[i-1] for i in range(-10, -5))
        consolidation = max(highs_list[-5:]) - min(lows_list[-5:]) < 0.02 * closes_list[-1]
        if uptrend and consolidation:
            pattern = 'Flag'
    
    return pattern

def interpret_candlestick_patterns(patterns, current_price, ema50):
    """Ph√¢n t√≠ch √Ω nghƒ©a c·ªßa c√°c m√¥ h√¨nh n·∫øn v√† ƒë∆∞a ra k·∫øt lu·∫≠n c·ª• th·ªÉ"""
    bullish_patterns = ['Hammer', 'Bullish Engulfing', 'Morning Star', 'Three White Soldiers']
    bearish_patterns = ['Shooting Star', 'Bearish Engulfing', 'Evening Star', 'Three Black Crows']
    neutral_patterns = ['Doji', 'Spinning Top']
    
    bullish_count = sum(1 for p in patterns if p in bullish_patterns)
    bearish_count = sum(1 for p in patterns if p in bearish_patterns)
    neutral_count = sum(1 for p in patterns if p in neutral_patterns)
    
    # Ph√¢n t√≠ch chi ti·∫øt t·ª´ng m√¥ h√¨nh
    analysis = []
    
    for pattern in patterns:
        if pattern == 'Doji':
            if current_price > ema50:
                analysis.append("Doji ·ªü v√πng kh√°ng c·ª± ‚Üí C·∫£nh b√°o ƒë·∫£o chi·ªÅu gi·∫£m")
            else:
                analysis.append("Doji ·ªü v√πng h·ªó tr·ª£ ‚Üí C·∫£nh b√°o ƒë·∫£o chi·ªÅu tƒÉng")
        elif pattern == 'Hammer':
            analysis.append("Hammer ‚Üí T√≠n hi·ªáu ƒë·∫£o chi·ªÅu tƒÉng m·∫°nh")
        elif pattern == 'Shooting Star':
            analysis.append("Shooting Star ‚Üí T√≠n hi·ªáu ƒë·∫£o chi·ªÅu gi·∫£m m·∫°nh")
        elif pattern == 'Bullish Engulfing':
            analysis.append("Bullish Engulfing ‚Üí T√≠n hi·ªáu tƒÉng m·∫°nh, ƒë·∫£o chi·ªÅu t·ª´ gi·∫£m")
        elif pattern == 'Bearish Engulfing':
            analysis.append("Bearish Engulfing ‚Üí T√≠n hi·ªáu gi·∫£m m·∫°nh, ƒë·∫£o chi·ªÅu t·ª´ tƒÉng")
        elif pattern == 'Morning Star':
            analysis.append("Morning Star ‚Üí T√≠n hi·ªáu ƒë·∫£o chi·ªÅu tƒÉng r·∫•t m·∫°nh")
        elif pattern == 'Evening Star':
            analysis.append("Evening Star ‚Üí T√≠n hi·ªáu ƒë·∫£o chi·ªÅu gi·∫£m r·∫•t m·∫°nh")
        elif pattern == 'Three White Soldiers':
            analysis.append("Three White Soldiers ‚Üí Xu h∆∞·ªõng tƒÉng m·∫°nh ti·∫øp di·ªÖn")
        elif pattern == 'Three Black Crows':
            analysis.append("Three Black Crows ‚Üí Xu h∆∞·ªõng gi·∫£m m·∫°nh ti·∫øp di·ªÖn")
        elif pattern == 'Spinning Top':
            analysis.append("Spinning Top ‚Üí L∆∞·ª°ng l·ª±, c·∫ßn x√°c nh·∫≠n th√™m")
    
    # K·∫øt lu·∫≠n t·ªïng th·ªÉ
    if bullish_count > bearish_count and bullish_count > 0:
        conclusion = f"üü¢ T√çN HI·ªÜU TƒÇNG: {bullish_count} m√¥ h√¨nh bullish vs {bearish_count} bearish"
    elif bearish_count > bullish_count and bearish_count > 0:
        conclusion = f"üî¥ T√çN HI·ªÜU GI·∫¢M: {bearish_count} m√¥ h√¨nh bearish vs {bullish_count} bullish"
    elif neutral_count > 0 and bullish_count == 0 and bearish_count == 0:
        conclusion = f"üü° L∆Ø·ª†NG L·ª∞: {neutral_count} m√¥ h√¨nh trung t√≠nh"
    else:
        conclusion = "‚ö™ KH√îNG C√ì M√î H√åNH N·∫æN R√ï R√ÄNG"
    
    return {
        'patterns': patterns,
        'analysis': analysis,
        'conclusion': conclusion,
        'bullish_count': bullish_count,
        'bearish_count': bearish_count,
        'neutral_count': neutral_count
    }

def detect_candlestick_patterns(opens, highs, lows, closes):
    """Ph√°t hi·ªán c√°c m√¥ h√¨nh n·∫øn Nh·∫≠t"""
    patterns = []
    
    # Chuy·ªÉn ƒë·ªïi sang list n·∫øu l√† pandas Series
    opens_list = opens.tolist() if hasattr(opens, 'tolist') else opens
    highs_list = highs.tolist() if hasattr(highs, 'tolist') else highs
    lows_list = lows.tolist() if hasattr(lows, 'tolist') else lows
    closes_list = closes.tolist() if hasattr(closes, 'tolist') else closes
    
    # N·∫øn ƒë∆°n
    body_size = abs(opens_list[-1] - closes_list[-1])
    candle_range = highs_list[-1] - lows_list[-1]
    if candle_range > 0:
        # Doji
        if body_size / candle_range < 0.1:
            patterns.append('Doji')
        # Hammer
        if (closes_list[-1] > opens_list[-1] and 
            (highs_list[-1] - closes_list[-1]) / candle_range < 0.2 and 
            (opens_list[-1] - lows_list[-1]) / candle_range > 0.6):
            patterns.append('Hammer')
        # Shooting Star
        if (closes_list[-1] < opens_list[-1] and 
            (highs_list[-1] - opens_list[-1]) / candle_range > 0.6 and 
            (closes_list[-1] - lows_list[-1]) / candle_range < 0.2):
            patterns.append('Shooting Star')
        # Spinning Top
        if body_size / candle_range < 0.3 and (highs_list[-1] - closes_list[-1]) / candle_range > 0.3 and (opens_list[-1] - lows_list[-1]) / candle_range > 0.3:
            patterns.append('Spinning Top')

    # N·∫øn ƒë√¥i
    if len(opens_list) >= 2:
        # Bullish Engulfing
        if (closes_list[-2] < opens_list[-2] and closes_list[-1] > opens_list[-1] and 
            closes_list[-1] > opens_list[-2] and opens_list[-1] < closes_list[-2]):
            patterns.append('Bullish Engulfing')
        # Bearish Engulfing
        if (closes_list[-2] > opens_list[-2] and closes_list[-1] < opens_list[-1] and 
            closes_list[-1] < opens_list[-2] and opens_list[-1] > closes_list[-2]):
            patterns.append('Bearish Engulfing')

    # N·∫øn ba
    if len(opens_list) >= 3:
        # Morning Star
        if (closes_list[-3] < opens_list[-3] and 
            abs(closes_list[-2] - opens_list[-2]) / (highs_list[-2] - lows_list[-2]) < 0.3 and 
            closes_list[-1] > opens_list[-1] and closes_list[-1] > (highs_list[-3] + lows_list[-3]) / 2):
            patterns.append('Morning Star')
        # Evening Star
        if (closes_list[-3] > opens_list[-3] and 
            abs(closes_list[-2] - opens_list[-2]) / (highs_list[-2] - lows_list[-2]) < 0.3 and 
            closes_list[-1] < opens_list[-1] and closes_list[-1] < (highs_list[-3] + lows_list[-3]) / 2):
            patterns.append('Evening Star')
        # Three White Soldiers
        if (all(closes_list[i] > opens_list[i] and closes_list[i] > closes_list[i-1] for i in [-3, -2, -1]) and
            all((highs_list[i] - closes_list[i]) / (highs_list[i] - lows_list[i]) < 0.2 for i in [-3, -2, -1])):
            patterns.append('Three White Soldiers')
        # Three Black Crows
        if (all(closes_list[i] < opens_list[i] and closes_list[i] < closes_list[i-1] for i in [-3, -2, -1]) and
            all((closes_list[i] - lows_list[i]) / (highs_list[i] - lows_list[i]) < 0.2 for i in [-3, -2, -1])):
            patterns.append('Three Black Crows')

    return patterns

def detect_elliott_wave(highs, lows, closes):
    """Ph√°t hi·ªán m√¥ h√¨nh Elliott Wave ƒë∆°n gi·∫£n"""
    wave_pattern = 'None'
    
    # Chuy·ªÉn ƒë·ªïi sang list n·∫øu l√† pandas Series
    closes_list = closes.tolist() if hasattr(closes, 'tolist') else closes
    
    if len(closes_list) >= 10:
        # T√¨m 5 s√≥ng tƒÉng (Wave 1-5)
        waves = []
        current_wave = 0
        wave_start = 0
        
        for i in range(1, len(closes_list)):
            if closes_list[i] > closes_list[i-1]:  # S√≥ng tƒÉng
                if current_wave == 0 or current_wave % 2 == 0:  # B·∫Øt ƒë·∫ßu s√≥ng m·ªõi
                    current_wave += 1
                    wave_start = i-1
            elif closes_list[i] < closes_list[i-1]:  # S√≥ng gi·∫£m
                if current_wave % 2 == 1:  # K·∫øt th√∫c s√≥ng tƒÉng
                    waves.append((wave_start, i-1, 'up'))
                    current_wave += 1
                    wave_start = i-1
        
        # Ki·ªÉm tra m√¥ h√¨nh 5 s√≥ng
        if len(waves) >= 5:
            # Ki·ªÉm tra quy t·∫Øc c∆° b·∫£n c·ªßa Elliott Wave
            wave1_length = waves[0][1] - waves[0][0]
            wave3_length = waves[2][1] - waves[2][0]
            wave5_length = waves[4][1] - waves[4][0]
            
            # Wave 3 th∆∞·ªùng l√† s√≥ng d√†i nh·∫•t
            if wave3_length > wave1_length and wave3_length > wave5_length:
                wave_pattern = 'Elliott Wave 5 (Bullish)'
            else:
                wave_pattern = 'Elliott Wave 5 (Weak)'
    
    return wave_pattern

def analyze_timeframe(data, timeframe, current_price, symbol=None):
    """Ph√¢n t√≠ch k·ªπ thu·∫≠t t·ªëi ∆∞u v·ªõi 12 ch·ªâ s·ªë c·ªët l√µi, ML v√† ph√¢n t√≠ch h·ªôi t·ª•"""
    # Kh·ªüi t·∫°o commodity_signals ƒë·ªÉ tr√°nh l·ªói NameError
    commodity_signals = {}
    
    # Chuy·ªÉn ƒë·ªïi numpy array sang pandas Series ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi th∆∞ vi·ªán ta
    close = pd.Series(data['close'])
    high = pd.Series(data['high'])
    low = pd.Series(data['low'])
    volume = pd.Series(data['volume'])
    open = pd.Series(data['open'])
    
    # Helper function ƒë·ªÉ l·∫•y gi√° tr·ªã cu·ªëi c√πng
    def get_last(series):
        return series.iloc[-1] if hasattr(series, 'iloc') else series[-1]
    
    def get_last_n(series, n):
        if hasattr(series, 'iloc'):
            return series.iloc[-n:].tolist()
        else:
            return series[-n:]

    # === 1. TREND INDICATORS (3 ch·ªâ s·ªë c·ªët l√µi) ===
    ema20 = ta.trend.ema_indicator(close, window=20)              # Trend ng·∫Øn h·∫°n
    ema50 = ta.trend.ema_indicator(close, window=50)              # Trend trung h·∫°n  
    adx = ta.trend.adx(high, low, close, window=7)      # Trend strength

    # === 2. MOMENTUM INDICATORS (3 ch·ªâ s·ªë c·ªët l√µi) ===
    rsi = ta.momentum.rsi(close, window=7)                 # Momentum chu·∫©n
    stoch_k = ta.momentum.stoch(high, low, close, window=7)  # Stochastic %K
    stoch_d = ta.momentum.stoch_signal(high, low, close, window=7)  # Stochastic %D
    macd_line = ta.trend.macd(close, window_fast=6, window_slow=13)  # MACD line
    macd_signal = ta.trend.macd_signal(close, window_fast=6, window_slow=13, window_sign=4)  # MACD signal
    macd_hist = ta.trend.macd_diff(close, window_fast=6, window_slow=13, window_sign=4)  # MACD histogram

    # === 3. VOLATILITY INDICATORS (2 ch·ªâ s·ªë c·ªët l√µi) ===
    bb_upper = ta.volatility.bollinger_hband(close, window=10, window_dev=2)       # BB Upper
    bb_middle = ta.volatility.bollinger_mavg(close, window=10)       # BB Middle
    bb_lower = ta.volatility.bollinger_lband(close, window=10, window_dev=2)       # BB Lower
    atr = ta.volatility.average_true_range(high, low, close, window=7)      # Volatility thu·∫ßn

    # === 4. VOLUME INDICATORS (2 ch·ªâ s·ªë c·ªët l√µi) ===
    obv = ta.volume.on_balance_volume(close, volume)                   # Volume flow
    vwap = calculate_vwap(high, low, close, volume) # Volume price level

    # === 5. SUPPORT/RESISTANCE (2 ch·ªâ s·ªë c·ªët l√µi) ===
    pivot_points = calculate_pivot_points(high, low, close)
    support, resistance = find_support_resistance(high, low, current_price)

    # === 6. M√î H√åNH GI√Å V√Ä N·∫æN ===
    price_pattern = detect_price_patterns(high, low, close)
    candlestick_patterns = detect_candlestick_patterns(open, high, low, close)
    
    # === 7. SMART MONEY CONCEPTS ===
    order_blocks = detect_order_blocks(high, low, close, volume)
    fvgs = detect_fair_value_gaps(high, low, close)
    liquidity_zones = detect_liquidity_zones(high, low, close, volume)
    mitigation_zones = detect_mitigation_zones(high, low, close)
    
    # Ph√¢n t√≠ch SMC v√† Price Action
    smc_signals = analyze_smc_signals(current_price, order_blocks, fvgs, liquidity_zones, mitigation_zones)
    
    # === 8. PH√ÇN T√çCH DIVERGENCE/CONVERGENCE - TR·ªåNG S·ªê CAO ===
    divergences = analyze_all_divergences(close, rsi, macd_line, volume)
    divergence_consensus = calculate_divergence_consensus(divergences)
    
    # === 9. T√çNH TO√ÅN T√çN HI·ªÜU C∆† B·∫¢N ===
    
    # RSI Signal
    rsi_signal = 'Hold'
    if get_last(rsi) < 25:
        rsi_signal = 'Long'
    elif get_last(rsi) > 75:
        rsi_signal = 'Short'
    
    # Stochastic Signal
    stoch_signal = 'Hold'
    if get_last(stoch_k) < 20 and get_last(stoch_k) > get_last(stoch_d):
        stoch_signal = 'Long'
    elif get_last(stoch_k) > 80 and get_last(stoch_k) < get_last(stoch_d):
        stoch_signal = 'Short'

    # MACD Signal
    macd_signal = 'Hold'
    try:
        macd_line_last_2 = get_last_n(macd_line, 2)
        macd_signal_last_2 = get_last_n(macd_signal, 2)
        if (not np.isnan(macd_line_last_2[0]) and not np.isnan(macd_signal_last_2[0]) and
            macd_line_last_2[0] < macd_signal_last_2[0] and get_last(macd_line) > get_last(macd_signal)):
            macd_signal = 'Long'
        elif (not np.isnan(macd_line_last_2[0]) and not np.isnan(macd_signal_last_2[0]) and
              macd_line_last_2[0] > macd_signal_last_2[0] and get_last(macd_line) < get_last(macd_signal)):
            macd_signal = 'Short'
    except:
        pass

    # MA Signal
    ma_signal = 'Hold'
    ma_distance = abs(get_last(ema20) - get_last(ema50)) / get_last(ema50)
    if get_last(ema20) > get_last(ema50) and ma_distance > 0.01:
        ma_signal = 'Long'
    elif get_last(ema20) < get_last(ema50) and ma_distance > 0.01:
        ma_signal = 'Short'

    # ADX Signal
    adx_signal = 'Hold'
    if get_last(adx) > 25:
        if get_last(close) > get_last(ema20):
            adx_signal = 'Long'
        elif get_last(close) < get_last(ema20):
            adx_signal = 'Short'

    # Bollinger Bands Signal
    bb_signal = 'Hold'
    if current_price <= get_last(bb_lower) * 0.995:
        bb_signal = 'Long'
    elif current_price >= get_last(bb_upper) * 1.005:
        bb_signal = 'Short'

    # OBV Signal
    obv_signal = 'Hold'
    obv_slope = get_last(obv) - get_last_n(obv, 10)[0]
    obv_change = obv_slope / get_last_n(obv, 10)[0] if get_last_n(obv, 10)[0] != 0 else 0
    if obv_change > 0.05 and get_last(close) > get_last(ema50):
        obv_signal = 'Long'
    elif obv_change < -0.05 and get_last(close) < get_last(ema50):
        obv_signal = 'Short'

    # VWAP Signal
    vwap_signal = 'Hold'
    vwap_distance = abs(current_price - vwap) / vwap
    if current_price > vwap and vwap_distance > 0.02:
        vwap_signal = 'Long'
    elif current_price < vwap and vwap_distance > 0.02:
        vwap_signal = 'Short'

    # ATR Signal
    atr_signal = 'Hold'
    atr_avg = np.mean(get_last_n(atr, 10))
    if get_last(atr) > atr_avg * 1.5:
        if get_last(close) > get_last(ema50):
            atr_signal = 'Long'
        elif get_last(close) < get_last(ema50):
            atr_signal = 'Short'

    # Pivot Points Signal
    pivot_signal = 'Hold'
    pivot_distance = min(abs(current_price - pivot_points['s1']), abs(current_price - pivot_points['r1'])) / current_price
    if current_price < pivot_points['s1'] and pivot_distance > 0.01:
        pivot_signal = 'Long'
    elif current_price > pivot_points['r1'] and pivot_distance > 0.01:
        pivot_signal = 'Short'

    # Candlestick Signal
    candlestick_signal = 'Hold'
    if any(p in ['Hammer', 'Bullish Engulfing', 'Morning Star', 'Three White Soldiers'] for p in candlestick_patterns):
        candlestick_signal = 'Long'
    elif any(p in ['Shooting Star', 'Bearish Engulfing', 'Evening Star', 'Three Black Crows'] for p in candlestick_patterns):
        candlestick_signal = 'Short'

    # Price Pattern Signal
    price_pattern_signal = 'Hold'
    if price_pattern in ['Head and Shoulders', 'Double Top']:
        price_pattern_signal = 'Short'
    elif price_pattern == 'Flag' and get_last(close) > get_last(ema50):
        price_pattern_signal = 'Long'

    # === 10. T√çN HI·ªÜU ƒê·∫∂C BI·ªÜT CHO H√ÄNG H√ìA ===
    # ƒê√£ lo·∫°i b·ªè code li√™n quan ƒë·∫øn v√†ng v√† d·∫ßu

    # === 11. T·∫†O DANH S√ÅCH T√çN HI·ªÜU C∆† B·∫¢N ===
    basic_signals = [
        rsi_signal, stoch_signal, macd_signal, ma_signal, adx_signal,
        bb_signal, obv_signal, vwap_signal, atr_signal, pivot_signal,
        candlestick_signal, price_pattern_signal,
        smc_signals['order_block_signal'], smc_signals['fvg_signal'], 
        smc_signals['liquidity_signal'], smc_signals['mitigation_signal']
    ]

    # === 12. X·ª¨ L√ù DIVERGENCE V·ªöI TR·ªåNG S·ªê CAO ===
    divergence_signal = divergence_consensus['signal']
    divergence_strength = divergence_consensus['strength']
    divergence_count = divergence_consensus['count']
    
    # T·∫°o danh s√°ch t√≠n hi·ªáu cu·ªëi c√πng v·ªõi tr·ªçng s·ªë divergence
    final_signals = basic_signals.copy()
    
    # N·∫†NG CAO TR·ªåNG S·ªê CHO DIVERGENCE
    if divergence_signal != 'Hold' and divergence_strength > 0.2:
        # Th√™m divergence signal nhi·ªÅu l·∫ßn d·ª±a tr√™n strength
        divergence_weight = int(divergence_strength * 10)  # TƒÉng t·ª´ 5 l√™n 10
        for _ in range(divergence_weight):
            final_signals.append(divergence_signal)
        
        # Th√™m c·∫£nh b√°o ƒë·∫∑c bi·ªát cho divergence m·∫°nh
        if divergence_strength > 0.5:
            # Th√™m th√™m 5 l·∫ßn n·ªØa cho divergence r·∫•t m·∫°nh
            for _ in range(5):
                final_signals.append(divergence_signal)

    # === 13. T√çN HI·ªÜU C·ª∞C M·∫†NH (EXTRA WEIGHT) ===
    extra_signals = []
    
    # RSI c·ª±c m·∫°nh
    if get_last(rsi) < 20:
        extra_signals.extend(['Long', 'Long', 'Long'])
    elif get_last(rsi) > 80:
        extra_signals.extend(['Short', 'Short', 'Short'])
    
    # Stochastic c·ª±c m·∫°nh
    if get_last(stoch_k) < 10:
        extra_signals.extend(['Long', 'Long', 'Long'])
    elif get_last(stoch_k) > 90:
        extra_signals.extend(['Short', 'Short', 'Short'])
    
    # Bollinger Bands breakout m·∫°nh
    if current_price < get_last(bb_lower) * 0.985:
        extra_signals.extend(['Long', 'Long', 'Long'])
    elif current_price > get_last(bb_upper) * 1.015:
        extra_signals.extend(['Short', 'Short', 'Short'])
    
    # MACD crossover m·∫°nh
    try:
        if (get_last(macd_line) > get_last(macd_signal) * 1.2 and 
            get_last_n(macd_line, 2)[0] <= get_last_n(macd_signal, 2)[0]):
            extra_signals.extend(['Long', 'Long', 'Long'])
        elif (get_last(macd_line) < get_last(macd_signal) * 0.8 and 
              get_last_n(macd_line, 2)[0] >= get_last_n(macd_signal, 2)[0]):
            extra_signals.extend(['Short', 'Short', 'Short'])
    except:
        pass

    # === 14. T√çNH TO√ÅN CONSENSUS CU·ªêI C√ôNG ===
    all_signals = final_signals + extra_signals
    
    long_count = all_signals.count('Long')
    short_count = all_signals.count('Short')
    hold_count = all_signals.count('Hold')
    
    total_signals = len(all_signals)
    
    if total_signals == 0:
        consensus = 'Hold'
        confidence = 0.0
    else:
        if long_count > short_count:
            consensus = 'Long'
            confidence = long_count / total_signals
        elif short_count > long_count:
            consensus = 'Short'
            confidence = short_count / total_signals
        else:
            consensus = 'Hold'
            confidence = 0.5

    # === 15. T√çNH TO√ÅN ƒêI·ªÇM ENTRY ===
    entry_points = calculate_entry_points(current_price, high, low, close, rsi, bb_upper, bb_lower, ema50, pivot_points, support, resistance)

    # === 15. MACHINE LEARNING PREDICTION ===
    ml_prediction = None
    try:
        # Ch·ªâ s·ª≠ d·ª•ng ML cho c√°c timeframe ƒë√£ ƒë∆∞·ª£c train
        if timeframe in ML_TIMEFRAMES:
            ml_prediction = predict_with_ml(symbol, timeframe, data)
            if ml_prediction and ml_prediction['confidence'] > ML_CONFIDENCE_THRESHOLD:
                # Th√™m t√≠n hi·ªáu ML v√†o danh s√°ch v·ªõi tr·ªçng s·ªë cao
                ml_weight = int(ml_prediction['confidence'] * 5)  # Tr·ªçng s·ªë d·ª±a tr√™n confidence
                for _ in range(ml_weight):
                    final_signals.append(ml_prediction['signal'])
                logger.info(f"ü§ñ ML {ml_prediction['model_name']}: {ml_prediction['signal']} (Confidence: {ml_prediction['confidence']:.3f})")
        else:
            logger.debug(f"‚è≠Ô∏è B·ªè qua ML prediction cho {symbol} ({timeframe}) - kh√¥ng c√≥ model ƒë∆∞·ª£c train")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è L·ªói ML prediction cho {symbol}: {e}")

    # === 16. PH√ÇN T√çCH H·ªòI T·ª§ (CONVERGENCE ANALYSIS) ===
    convergence_analysis = None
    try:
        convergence_analysis = analyze_convergence(data)
        if convergence_analysis and convergence_analysis['overall_convergence'] > CONVERGENCE_THRESHOLD:
            # Th√™m t√≠n hi·ªáu convergence v√†o danh s√°ch
            convergence_weight = int(convergence_analysis['strength'] * 3)
            for signal_info in convergence_analysis['signals']:
                for _ in range(convergence_weight):
                    final_signals.append(signal_info['signal'])
            logger.info(f"üéØ Convergence Analysis: {convergence_analysis['overall_convergence']:.3f} - {len(convergence_analysis['signals'])} signals")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è L·ªói convergence analysis cho {symbol}: {e}")

    # === 17. T√çNH TO√ÅN CONSENSUS CU·ªêI C√ôNG (C·∫¨P NH·∫¨T) ===
    all_signals = final_signals + extra_signals
    
    long_count = all_signals.count('Long')
    short_count = all_signals.count('Short')
    hold_count = all_signals.count('Hold')
    
    total_signals = len(all_signals)
    
    if total_signals == 0:
        consensus = 'Hold'
        confidence = 0.0
    else:
        if long_count > short_count:
            consensus = 'Long'
            confidence = long_count / total_signals
        elif short_count > long_count:
            consensus = 'Short'
            confidence = short_count / total_signals
        else:
            consensus = 'Hold'
            confidence = 0.5

    # === 18. TR·∫¢ V·ªÄ K·∫æT QU·∫¢ T·ªêI ∆ØU ===
    return {
        'trend': 'bullish' if consensus == 'Long' else 'bearish' if consensus == 'Short' else 'neutral',
        'signal': consensus,
        'confidence': confidence,
        'consensus_ratio': confidence,  # Th√™m consensus_ratio ƒë·ªÉ t∆∞∆°ng th√≠ch
        'strength': divergence_strength,
        'timeframe': timeframe,  # Th√™m timeframe v√†o k·∫øt qu·∫£
        'indicators': {
            'rsi': get_last(rsi),
            'stoch_k': get_last(stoch_k),
            'stoch_d': get_last(stoch_d),
            'macd_line': get_last(macd_line),
            'macd_signal': get_last(macd_signal),
            'ema20': get_last(ema20),
            'ema50': get_last(ema50),
            'adx': get_last(adx),
            'bb_upper': get_last(bb_upper),
            'bb_middle': get_last(bb_middle),
            'bb_lower': get_last(bb_lower),
            'atr': get_last(atr),
            'obv': get_last(obv),
            'vwap': vwap,
            'support': support,
            'resistance': resistance
        },
        'signals': {
            'rsi': rsi_signal,
            'stoch': stoch_signal,
            'macd': macd_signal,
            'ma': ma_signal,
            'adx': adx_signal,
            'bb': bb_signal,
            'obv': obv_signal,
            'vwap': vwap_signal,
            'atr': atr_signal,
            'pivot': pivot_signal,
            'candlestick': candlestick_signal,
            'pattern': price_pattern_signal
        },
        'divergences': divergences,
        'divergence_consensus': divergence_consensus,
        'ml_prediction': ml_prediction,
        'convergence_analysis': convergence_analysis,
        'entry_points': entry_points,
        'price_pattern': price_pattern,
        'candlestick_patterns': candlestick_patterns,
        'smc_signals': smc_signals,
        'commodity_signals': commodity_signals,
        'signal_counts': {
            'long': long_count,
            'short': short_count,
            'hold': hold_count,
            'total': total_signals
        }
    }

def make_decision(analyses):
    """T·ªïng h·ª£p nh·∫≠n ƒë·ªãnh t·ª´ c√°c khung th·ªùi gian
    
    Logic:
    - SIGNAL_THRESHOLD (50%): Ng∆∞·ª°ng t·ªëi thi·ªÉu ƒë·ªÉ m·ªôt timeframe ƒë∆∞·ª£c coi l√† c√≥ t√≠n hi·ªáu h·ª£p l·ªá
    - consensus_ratio: T·ª∑ l·ªá ƒë·ªìng thu·∫≠n th·ª±c t·∫ø c·ªßa timeframe c√≥ t√≠n hi·ªáu m·∫°nh nh·∫•t
    - Ch·ªâ nh·ªØng timeframe c√≥ consensus_ratio >= SIGNAL_THRESHOLD m·ªõi ƒë∆∞·ª£c x√©t
    """
    valid_timeframes = []
    for analysis in analyses:
        if analysis['signal'] in ['Long', 'Short'] and analysis['consensus_ratio'] >= SIGNAL_THRESHOLD:
            valid_timeframes.append(analysis)
    
    if valid_timeframes:
        signals = [a['signal'] for a in valid_timeframes]
        has_long = 'Long' in signals
        has_short = 'Short' in signals
        if has_long and has_short:
            return 'Mixed', 0, valid_timeframes
        best_analysis = max(valid_timeframes, key=lambda x: x['consensus_ratio'])
        return best_analysis['signal'], best_analysis['consensus_ratio'], valid_timeframes
    return 'Hold', 0, []

def analyze_coin(symbol):
    """Ph√¢n t√≠ch xu h∆∞·ªõng ng·∫Øn h·∫°n cho m·ªôt coin"""
    try:
        logger.info(f"üîç B·∫Øt ƒë·∫ßu ph√¢n t√≠ch {symbol}...")
        
        # L·∫•y gi√° hi·ªán t·∫°i cho crypto
        ticker = exchange.fetch_ticker(symbol)
        current_price = ticker['last']
        logger.info(f"‚úÖ ƒê√£ l·∫•y gi√° hi·ªán t·∫°i cho {symbol}: ${current_price}")
    except Exception as e:
        logger.error(f"L·ªói khi l·∫•y gi√° hi·ªán t·∫°i cho {symbol}: {e}")
        return None

    analyses = []
    for timeframe in TIMEFRAMES:
        logger.info(f"üìä ƒêang l·∫•y d·ªØ li·ªáu {symbol} cho timeframe {timeframe}...")
        data = fetch_ohlcv(symbol, timeframe, CANDLE_LIMIT)
        if data is None:
            logger.warning(f"‚ùå Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu cho {symbol} ({timeframe})")
            continue
        logger.info(f"‚úÖ ƒê√£ l·∫•y d·ªØ li·ªáu {symbol} ({timeframe}): {len(data['close'])} candles")
        
        analysis = analyze_timeframe(data, timeframe, current_price, symbol)
        
        # ƒêi·ªÅu ch·ªânh ph√¢n t√≠ch d·ª±a tr√™n ƒë·ªô ch√≠nh x√°c l·ªãch s·ª≠
        analysis = adjust_analysis_based_on_accuracy(analysis, symbol, timeframe)
        
        analyses.append(analysis)

    if not analyses:
        logger.debug(f"B·ªè qua {symbol}: kh√¥ng c√≥ d·ªØ li·ªáu t·ª´ b·∫•t k·ª≥ timeframe n√†o")
        return None

    decision, consensus_ratio, valid_timeframes = make_decision(analyses)

    # T·∫°o k·∫øt qu·∫£ ph√¢n t√≠ch
    result = {
        'symbol': symbol,
        'decision': decision,
        'consensus_ratio': consensus_ratio,
        'valid_timeframes': valid_timeframes,
        'analyses': analyses,
        'current_price': current_price
    }

    # L∆∞u d·ª± ƒëo√°n cho c√°c timeframe c√≥ t√≠n hi·ªáu m·∫°nh
    for analysis in valid_timeframes:
        if analysis['consensus_ratio'] >= SIGNAL_THRESHOLD:
            prediction_data = {
                'trend': analysis.get('trend', 'neutral'),
                'signal': analysis.get('signal', 'Hold'),
                'confidence': analysis.get('confidence', 0),
                'entry_points': analysis.get('entry_points', {}),
                'analysis_summary': f"Timeframe: {analysis['timeframe']}, Consensus: {analysis['consensus_ratio']:.1%}",
                'technical_signals': {
                    'rsi_signal': analysis.get('rsi_signal', 'Hold'),
                    'macd_signal': analysis.get('macd_signal', 'Hold'),
                    'bb_signal': analysis.get('bb_signal', 'Hold'),
                    'stoch_signal': analysis.get('stoch_signal', 'Hold')
                },
                'commodity_signals': analysis.get('commodity_signals', {}),
                'smc_signals': analysis.get('smc_signals', {}),
                'price_action_signals': analysis.get('pa_signals', {})
            }
            
            # L∆∞u d·ª± ƒëo√°n
            prediction_id = save_prediction(symbol, analysis['timeframe'], prediction_data, current_price)
            if prediction_id:
                logger.info(f"üìù ƒê√£ l∆∞u d·ª± ƒëo√°n {prediction_id} cho {symbol} ({analysis['timeframe']})")

    return result

def send_telegram_message(message):
    """G·ª≠i tin nh·∫Øn qua Telegram Bot"""
    logger.info(f"üîç DEBUG: B·∫Øt ƒë·∫ßu g·ª≠i Telegram message")
    logger.info(f"üîç DEBUG: TELEGRAM_BOT_TOKEN = {TELEGRAM_BOT_TOKEN[:10]}...")
    logger.info(f"üîç DEBUG: TELEGRAM_CHAT_ID = {TELEGRAM_CHAT_ID}")
    
    if TELEGRAM_BOT_TOKEN == "YOUR_BOT_TOKEN_HERE" or TELEGRAM_CHAT_ID == "YOUR_CHAT_ID_HERE":
        logger.warning("Ch∆∞a c·∫•u h√¨nh Telegram Bot Token ho·∫∑c Chat ID")
        return False
    
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        data = {
            'chat_id': TELEGRAM_CHAT_ID,
            'text': message,
            'parse_mode': 'HTML'
        }
        logger.info(f"üîç DEBUG: G·ª≠i request ƒë·∫øn {url}")
        logger.info(f"üîç DEBUG: Data = {data}")
        
        response = requests.post(url, data=data, timeout=10)
        logger.info(f"üîç DEBUG: Response status = {response.status_code}")
        logger.info(f"üîç DEBUG: Response text = {response.text}")
        
        if response.status_code == 200:
            logger.info("‚úÖ ƒê√£ g·ª≠i b√°o c√°o qua Telegram th√†nh c√¥ng")
            return True
        else:
            logger.error(f"‚ùå L·ªói khi g·ª≠i Telegram: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi g·ª≠i Telegram: {e}")
        return False

def format_coin_report(result):
    """ƒê·ªãnh d·∫°ng b√°o c√°o ph√¢n t√≠ch cho m·ªôt ƒë·ªìng coin, v√†ng ho·∫∑c d·∫ßu c·ª• th·ªÉ - T·ªëi ∆∞u cho t√≠n hi·ªáu m·∫°nh"""
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    symbol = result['symbol']
    decision = result['decision']
    consensus_ratio = result['consensus_ratio']
    valid_timeframes = result['valid_timeframes']
    
    # X√°c ƒë·ªãnh lo·∫°i t√†i s·∫£n ƒë·ªÉ hi·ªÉn th·ªã emoji ph√π h·ª£p
    asset_type = "COIN"
    
    report = f"ü§ñ <b>PH√ÇN T√çCH {asset_type} {symbol}</b>\n"
    report += f"‚è∞ {current_time} | üìä Ng∆∞·ª°ng t·ªëi thi·ªÉu: {SIGNAL_THRESHOLD:.1%}\n\n"
    
    if decision == 'Mixed':
        report += f"‚ö†Ô∏è <b>{symbol}: T√çN HI·ªÜU TR√ÅI CHI·ªÄU</b>\n"
        for analysis in valid_timeframes:
            report += f"  ‚Ä¢ {analysis['timeframe']}: {analysis['signal']} ({analysis['consensus_ratio']:.1%})\n"
    elif decision in ['Long', 'Short']:
        emoji = "‚úÖ" if decision == 'Long' else "üî¥"
        report += f"{emoji} <b>{symbol}: {decision}</b> (ƒê·ªìng thu·∫≠n: {consensus_ratio:.1%})\n"
        report += f"üìä Timeframes: {', '.join([a['timeframe'] for a in valid_timeframes])}\n"
        report += f"üí° T√≠n hi·ªáu t·ª´ timeframe c√≥ ƒë·ªìng thu·∫≠n cao nh·∫•t\n\n"
        
        # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ c√°c timeframe ƒë∆∞·ª£c ch·ªçn
        for analysis in valid_timeframes:
            report += f"üìä <b>{analysis['timeframe']}:</b> {analysis['signal']} (ƒê·ªìng thu·∫≠n: {analysis['consensus_ratio']:.1%})\n"
        report += "\n"
        
        # Ch·ªâ hi·ªÉn th·ªã c√°c t√≠n hi·ªáu m·∫°nh v√† quan tr·ªçng nh·∫•t
        for analysis in valid_timeframes:
            timeframe = analysis['timeframe']
            strong_signals = []
            
            # Divergence m·∫°nh - ∆Øu ti√™n cao nh·∫•t
            if analysis['divergence_consensus']['signal'] != 'Hold' and analysis['divergence_consensus']['strength'] > 0.3:
                strong_signals.append(f"Divergence ({analysis['divergence_consensus']['count']} signals)")
            
            # RSI c·ª±c m·∫°nh (15/85)
            if analysis['rsi_value'] < 15 or analysis['rsi_value'] > 85:
                strong_signals.append(f"RSI({analysis['rsi_value']:.1f})")
            
            # M√¥ h√¨nh n·∫øn m·∫°nh
            if analysis['candlestick_analysis']['conclusion'].startswith('üü¢') or analysis['candlestick_analysis']['conclusion'].startswith('üî¥'):
                strong_signals.append("M√¥ h√¨nh n·∫øn m·∫°nh")
            
            # MACD crossover m·∫°nh
            if analysis['macd_signal'] != 'Hold':
                strong_signals.append("MACD crossover")
            
            # Bollinger Bands breakout
            if analysis['bb_signal'] != 'Hold':
                strong_signals.append("BB breakout")
            
            # M√¥ h√¨nh gi√° quan tr·ªçng
            if analysis['price_pattern'] != 'None':
                strong_signals.append(f"M√¥ h√¨nh: {analysis['price_pattern']}")
            
            # SMC signals m·∫°nh
            if 'smc_signals' in analysis:
                smc = analysis['smc_signals']
                if smc['order_block_signal'] != 'Hold':
                    strong_signals.append("Order Block")
                if smc['fvg_signal'] != 'Hold':
                    strong_signals.append("Fair Value Gap")
            
            # Price Action m·∫°nh
            if 'pa_signals' in analysis:
                pa = analysis['pa_signals']
                if pa['pattern_signal'] != 'Hold':
                    strong_signals.append("Price Action")
            
            # Ch·ªâ b√°o h√†ng h√≥a m·∫°nh (cho v√†ng v√† d·∫ßu)
            if 'commodity_signals' in analysis and analysis['commodity_signals']:
                commodity = analysis['commodity_signals']
                if commodity.get('aroon_signal') != 'Hold':
                    strong_signals.append("Aroon")
                if commodity.get('csi_signal') != 'Hold':
                    strong_signals.append("CSI")
                if commodity.get('seasonal_signal') != 'Hold':
                    strong_signals.append("Seasonal")
            
            # Hi·ªÉn th·ªã t√≠n hi·ªáu m·∫°nh (t·ªëi ƒëa 5 t√≠n hi·ªáu quan tr·ªçng nh·∫•t)
            if strong_signals:
                report += f"üìä <b>{timeframe}:</b> {', '.join(strong_signals[:5])}\n"
            
            # Ch·ªâ hi·ªÉn th·ªã entry points cho timeframe c√≥ t√≠n hi·ªáu m·∫°nh nh·∫•t
            if analysis == max(valid_timeframes, key=lambda x: x['consensus_ratio']):
                if 'entry_points' in analysis:
                    entry = analysis['entry_points']
                    report += f"üéØ <b>ENTRY ({timeframe}):</b>\n"
                    report += f"  ‚Ä¢ Entry: ${entry['aggressive']:.4f}\n"
                    report += f"  ‚Ä¢ SL: ${entry['stop_loss']:.4f}\n"
                    report += f"  ‚Ä¢ TP: ${entry['take_profit']:.4f}\n"
            
            report += "\n"
    else:
        report += f"‚è∏Ô∏è {symbol}: Kh√¥ng c√≥ t√≠n hi·ªáu m·∫°nh\n"
    
    return report

def format_analysis_report(results):
    """ƒê·ªãnh d·∫°ng b√°o c√°o ph√¢n t√≠ch t·ªëi ∆∞u v·ªõi nh·∫•n m·∫°nh divergence/convergence"""
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # L·∫•y th·ªëng k√™ ƒë·ªô ch√≠nh x√°c
    accuracy_data = get_prediction_accuracy_data()
    accuracy_summary = ""
    if accuracy_data:
        overall = accuracy_data.get('overall', {})
        if overall.get('total_predictions', 0) > 0:
            accuracy_summary = f" | üìà ƒê·ªô ch√≠nh x√°c: {overall['accuracy']:.1%} ({overall['accurate_predictions']}/{overall['total_predictions']})"
    
    report = f"ü§ñ <b>B√ÅO C√ÅO PH√ÇN T√çCH XU H∆Ø·ªöNG T·ªêI ∆ØU</b>\n"
    report += f"‚è∞ Th·ªùi gian: {current_time}\n"
    report += f"üìä Ng∆∞·ª°ng t·ªëi thi·ªÉu: {SIGNAL_THRESHOLD:.1%}{accuracy_summary}\n"
    report += f"üí∞ T√†i s·∫£n: Crypto, V√†ng, D·∫ßu\n"
    report += f"üéØ <b>12 CH·ªà S·ªê C·ªêT L√ïI + ML + CONVERGENCE ANALYSIS</b>\n\n"
    
    if not results:
        report += "üìä Kh√¥ng c√≥ xu h∆∞·ªõng m·∫°nh n√†o ƒë∆∞·ª£c ph√°t hi·ªán."
        return report
    
    for result in results:
        symbol = result['symbol']
        decision = result['decision']
        consensus_ratio = result['consensus_ratio']
        valid_timeframes = result['valid_timeframes']
        
        if decision == 'Mixed':
            report += f"‚ö†Ô∏è <b>{symbol}: C√ì K·∫æT LU·∫¨N TR√ÅI CHI·ªÄU</b>\n"
            for analysis in valid_timeframes:
                report += f"  ‚Ä¢ {analysis['timeframe']}: {analysis['signal']} ({analysis['confidence']:.1%})\n"
        elif decision in ['Long', 'Short']:
            emoji = "‚úÖ" if decision == 'Long' else "üî¥"
            report += f"{emoji} <b>{symbol}: {decision}</b> (ƒê·ªô tin c·∫≠y: {consensus_ratio:.1%})\n"
            report += f"üìä Timeframes: {', '.join([a['timeframe'] for a in valid_timeframes])}\n"
            
            # Th√™m th√¥ng tin chi ti·∫øt cho t·ª´ng timeframe
            for analysis in valid_timeframes:
                timeframe = analysis['timeframe']
                report += f"\nüìä <b>Timeframe {timeframe}:</b>\n"
                
                # === 1. MACHINE LEARNING PREDICTION ===
                ml_prediction = analysis.get('ml_prediction')
                if ml_prediction and ml_prediction.get('confidence', 0) > ML_CONFIDENCE_THRESHOLD:
                    report += f"ü§ñ <b>MACHINE LEARNING PREDICTION:</b>\n"
                    report += f"  ‚Ä¢ Model: {ml_prediction['model_name']}\n"
                    report += f"  ‚Ä¢ T√≠n hi·ªáu: {ml_prediction['signal']}\n"
                    report += f"  ‚Ä¢ Confidence: {ml_prediction['confidence']:.3f}\n"
                    report += f"  ‚Ä¢ Accuracy: {ml_prediction['model_performance']['accuracy']:.3f}\n"
                    report += f"  ‚Ä¢ CV Score: {ml_prediction['model_performance']['cv_mean']:.3f}¬±{ml_prediction['model_performance']['cv_std']:.3f}\n\n"

                # === 2. CONVERGENCE ANALYSIS ===
                convergence_analysis = analysis.get('convergence_analysis')
                if convergence_analysis and convergence_analysis.get('overall_convergence', 0) > CONVERGENCE_THRESHOLD:
                    report += f"üéØ <b>CONVERGENCE ANALYSIS:</b>\n"
                    report += f"  ‚Ä¢ Overall Convergence: {convergence_analysis['overall_convergence']:.3f}\n"
                    report += f"  ‚Ä¢ Strength: {convergence_analysis['strength']:.3f}\n"
                    report += f"  ‚Ä¢ Signals: {len(convergence_analysis['signals'])}\n"
                    
                    for signal in convergence_analysis['signals']:
                        report += f"  ‚Ä¢ {signal['period']} periods: {signal['signal']} (Strength: {signal['strength']:.3f})\n"
                    report += "\n"

                # === 3. DIVERGENCE/CONVERGENCE - ∆ØU TI√äN CAO NH·∫§T ===
                divergence_consensus = analysis.get('divergence_consensus', {})
                if divergence_consensus.get('signal') != 'Hold' and divergence_consensus.get('strength', 0) > 0.2:
                    strength_emoji = "üî•" if divergence_consensus['strength'] > 0.5 else "‚ö°"
                    report += f"{strength_emoji} <b>DIVERGENCE/CONVERGENCE M·∫†NH:</b>\n"
                    report += f"  ‚Ä¢ T√≠n hi·ªáu: {divergence_consensus['signal']}\n"
                    report += f"  ‚Ä¢ ƒê·ªô m·∫°nh: {divergence_consensus['strength']:.2f}\n"
                    report += f"  ‚Ä¢ S·ªë l∆∞·ª£ng: {divergence_consensus['count']}\n"
                    
                    # Hi·ªÉn th·ªã chi ti·∫øt divergence
                    divergences = analysis.get('divergences', {})
                    for div_type, div_info in divergences.items():
                        if div_info.get('type') != 'None':
                            report += f"  ‚Ä¢ {div_type}: {div_info['type']} ({div_info['strength']:.2f})\n"
                    report += "\n"
                
                # === 2. CH·ªà S·ªê C·ªêT L√ïI ===
                signals = analysis.get('signals', {})
                indicators = analysis.get('indicators', {})
                
                # Trend Indicators
                report += f"üìà <b>TREND:</b>\n"
                report += f"  ‚Ä¢ MA: {signals.get('ma', 'Hold')} (EMA20: {indicators.get('ema20', 0):.4f})\n"
                report += f"  ‚Ä¢ ADX: {signals.get('adx', 'Hold')} ({indicators.get('adx', 0):.1f})\n"
                
                # Momentum Indicators
                report += f"üìä <b>MOMENTUM:</b>\n"
                report += f"  ‚Ä¢ RSI: {signals.get('rsi', 'Hold')} ({indicators.get('rsi', 0):.1f})\n"
                report += f"  ‚Ä¢ Stochastic: {signals.get('stoch', 'Hold')} (K: {indicators.get('stoch_k', 0):.1f})\n"
                report += f"  ‚Ä¢ MACD: {signals.get('macd', 'Hold')} ({indicators.get('macd_line', 0):.4f})\n"
                
                # Volatility Indicators
                report += f"üìâ <b>VOLATILITY:</b>\n"
                report += f"  ‚Ä¢ Bollinger Bands: {signals.get('bb', 'Hold')}\n"
                report += f"  ‚Ä¢ ATR: {signals.get('atr', 'Hold')} ({indicators.get('atr', 0):.4f})\n"
                
                # Volume Indicators
                report += f"üí∞ <b>VOLUME:</b>\n"
                report += f"  ‚Ä¢ OBV: {signals.get('obv', 'Hold')}\n"
                report += f"  ‚Ä¢ VWAP: {signals.get('vwap', 'Hold')} ({indicators.get('vwap', 0):.4f})\n"
                
                # Support/Resistance
                report += f"üéØ <b>SUPPORT/RESISTANCE:</b>\n"
                report += f"  ‚Ä¢ Pivot: {signals.get('pivot', 'Hold')}\n"
                report += f"  ‚Ä¢ Support: {indicators.get('support', 0):.4f}\n"
                report += f"  ‚Ä¢ Resistance: {indicators.get('resistance', 0):.4f}\n"
                
                # Patterns
                if analysis.get('price_pattern') != 'None':
                    report += f"üìä <b>M√î H√åNH GI√Å:</b> {analysis['price_pattern']}\n"
                
                if analysis.get('candlestick_patterns'):
                    report += f"üïØÔ∏è <b>M√î H√åNH N·∫æN:</b> {', '.join(analysis['candlestick_patterns'])}\n"
                
                # Smart Money Concepts
                smc_signals = analysis.get('smc_signals', {})
                if any(signal != 'Hold' for signal in smc_signals.values()):
                    report += f"üß† <b>SMART MONEY CONCEPTS:</b>\n"
                    for smc_type, smc_signal in smc_signals.items():
                        if smc_signal != 'Hold':
                            report += f"  ‚Ä¢ {smc_type}: {smc_signal}\n"
                
                # Commodity Signals (cho v√†ng v√† d·∫ßu)
                commodity_signals = analysis.get('commodity_signals', {})
                if commodity_signals:
                    report += f"üèÜ <b>CH·ªà S·ªê H√ÄNG H√ìA:</b>\n"
                    for comm_type, comm_signal in commodity_signals.items():
                        if comm_signal != 'Hold':
                            report += f"  ‚Ä¢ {comm_type}: {comm_signal}\n"
                
                # Signal Counts
                signal_counts = analysis.get('signal_counts', {})
                if signal_counts:
                    report += f"üìä <b>TH·ªêNG K√ä T√çN HI·ªÜU:</b>\n"
                    report += f"  ‚Ä¢ Long: {signal_counts.get('long', 0)}\n"
                    report += f"  ‚Ä¢ Short: {signal_counts.get('short', 0)}\n"
                    report += f"  ‚Ä¢ Hold: {signal_counts.get('hold', 0)}\n"
                    report += f"  ‚Ä¢ T·ªïng: {signal_counts.get('total', 0)}\n"
                
                # Entry Points
                if 'entry_points' in analysis:
                    entry = analysis['entry_points']
                    report += f"\nüéØ <b>ƒêI·ªÇM ENTRY H·ª¢P L√ù:</b>\n"
                    report += f"  ‚Ä¢ Entry b·∫£o th·ªß: ${entry['conservative']:.4f}\n"
                    report += f"  ‚Ä¢ Entry t√≠ch c·ª±c: ${entry['aggressive']:.4f}\n"
                    report += f"  ‚Ä¢ Stop Loss: ${entry['stop_loss']:.4f}\n"
                    report += f"  ‚Ä¢ Take Profit: ${entry['take_profit']:.4f}\n"
                    for analysis_line in entry['analysis']:
                        report += f"  {analysis_line}\n"
                
                report += "\n"  # Th√™m d√≤ng tr·ªëng gi·ªØa c√°c timeframe
        else:
            report += f"‚è∏Ô∏è {symbol}: Kh√¥ng c√≥ t√≠n hi·ªáu m·∫°nh\n"
        
        report += "\n"
    
    return report

def format_prediction_accuracy_report():
    """ƒê·ªãnh d·∫°ng b√°o c√°o th·ªëng k√™ ƒë·ªô ch√≠nh x√°c d·ª± ƒëo√°n"""
    accuracy_data = get_prediction_accuracy_data()
    if not accuracy_data:
        return "üìä Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªô ch√≠nh x√°c d·ª± ƒëo√°n"
    
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    report = f"üìà <b>B√ÅO C√ÅO ƒê·ªò CH√çNH X√ÅC D·ª∞ ƒêO√ÅN</b>\n"
    report += f"‚è∞ {current_time}\n\n"
    
    # Th·ªëng k√™ t·ªïng th·ªÉ
    overall = accuracy_data.get('overall', {})
    if overall.get('total_predictions', 0) > 0:
        report += f"üìä <b>TH·ªêNG K√ä T·ªîNG TH·ªÇ:</b>\n"
        report += f"  ‚Ä¢ T·ªïng d·ª± ƒëo√°n: {overall['total_predictions']}\n"
        report += f"  ‚Ä¢ D·ª± ƒëo√°n ch√≠nh x√°c: {overall['accurate_predictions']}\n"
        report += f"  ‚Ä¢ ƒê·ªô ch√≠nh x√°c: {overall['accuracy']:.1%}\n\n"
    
    # Th·ªëng k√™ theo symbol
    symbol_stats = accuracy_data.get('by_symbol', {})
    if symbol_stats:
        report += f"üí∞ <b>THEO T√ÄI S·∫¢N:</b>\n"
        for symbol, stats in symbol_stats.items():
            if stats['total'] > 0:
                emoji = "üü¢"
                report += f"  {emoji} {symbol}: {stats['accuracy']:.1%} ({stats['accurate']}/{stats['total']})\n"
        report += "\n"
    
    # Th·ªëng k√™ theo timeframe
    timeframe_stats = accuracy_data.get('by_timeframe', {})
    if timeframe_stats:
        report += f"‚è∞ <b>THEO TIMEFRAME:</b>\n"
        for timeframe, stats in timeframe_stats.items():
            if stats['total'] > 0:
                report += f"  üìä {timeframe}: {stats['accuracy']:.1%} ({stats['accurate']}/{stats['total']})\n"
    
    return report

def telegram_report_scheduler():
    """L·∫≠p l·ªãch g·ª≠i b√°o c√°o Telegram ƒë·ªãnh k·ª≥"""
    def send_periodic_report():
        while True:
            try:
                logger.info("üîÑ B·∫Øt ƒë·∫ßu ph√¢n t√≠ch ƒë·ªÉ g·ª≠i b√°o c√°o Telegram...")
                
                results = []
                for symbol in SYMBOLS:
                    result = analyze_coin(symbol)
                    if result:
                        results.append(result)
                
                # G·ª≠i b√°o c√°o ri√™ng cho t·ª´ng coin
                if results:
                    for result in results:
                        try:
                            coin_report = format_coin_report(result)
                            send_telegram_message(coin_report)
                            logger.info(f"üì± ƒê√£ g·ª≠i b√°o c√°o cho {result['symbol']}")
                            time.sleep(2)  # Ch·ªù 2 gi√¢y gi·ªØa c√°c tin nh·∫Øn
                        except Exception as e:
                            logger.error(f"L·ªói khi g·ª≠i b√°o c√°o cho {result['symbol']}: {e}")
                else:
                    logger.info("Kh√¥ng c√≥ k·∫øt qu·∫£ ph√¢n t√≠ch ƒë·ªÉ g·ª≠i b√°o c√°o")
                
                logger.info(f"‚è∞ Ch·ªù {TELEGRAM_REPORT_INTERVAL} gi√¢y ƒë·ªÉ g·ª≠i b√°o c√°o ti·∫øp theo...")
                time.sleep(TELEGRAM_REPORT_INTERVAL)
                
            except Exception as e:
                logger.error(f"L·ªói trong telegram_report_scheduler: {e}")
                time.sleep(60)  # Ch·ªù 1 ph√∫t n·∫øu c√≥ l·ªói
    
    # Kh·ªüi ƒë·ªông thread g·ª≠i b√°o c√°o ƒë·ªãnh k·ª≥
    report_thread = threading.Thread(target=send_periodic_report, daemon=True)
    report_thread.start()
    logger.info(f"üì± ƒê√£ kh·ªüi ƒë·ªông Telegram Report Scheduler (g·ª≠i b√°o c√°o m·ªói {TELEGRAM_REPORT_INTERVAL//3600} gi·ªù)")

def prediction_update_scheduler():
    """L·∫≠p l·ªãch c·∫≠p nh·∫≠t k·∫øt qu·∫£ d·ª± ƒëo√°n ƒë·ªãnh k·ª≥"""
    def update_predictions_periodically():
        while True:
            try:
                logger.info("üîÑ C·∫≠p nh·∫≠t k·∫øt qu·∫£ d·ª± ƒëo√°n...")
                
                # C·∫≠p nh·∫≠t k·∫øt qu·∫£ th·ª±c t·∫ø cho c√°c d·ª± ƒëo√°n
                update_prediction_results()
                
                # D·ªçn d·∫πp c√°c d·ª± ƒëo√°n c≈©
                cleanup_old_predictions()
                
                logger.info(f"‚è∞ Ch·ªù {PREDICTION_UPDATE_INTERVAL} gi√¢y ƒë·ªÉ c·∫≠p nh·∫≠t d·ª± ƒëo√°n ti·∫øp theo...")
                time.sleep(PREDICTION_UPDATE_INTERVAL)
                
            except Exception as e:
                logger.error(f"L·ªói trong prediction_update_scheduler: {e}")
                time.sleep(300)  # Ch·ªù 5 ph√∫t n·∫øu c√≥ l·ªói
    
    # Kh·ªüi ƒë·ªông thread c·∫≠p nh·∫≠t d·ª± ƒëo√°n ƒë·ªãnh k·ª≥
    prediction_thread = threading.Thread(target=update_predictions_periodically, daemon=True)
    prediction_thread.start()
    logger.info(f"üìä ƒê√£ kh·ªüi ƒë·ªông Prediction Update Scheduler (c·∫≠p nh·∫≠t m·ªói {PREDICTION_UPDATE_INTERVAL//3600} gi·ªù)")

def ml_model_trainer_scheduler():
    """L·∫≠p l·ªãch train ML models ƒë·ªãnh k·ª≥"""
    def train_models_periodically():
        while True:
            try:
                logger.info("ü§ñ B·∫Øt ƒë·∫ßu train ML models cho BTC v√† ETH...")
                
                # Ch·ªâ train cho BTC v√† ETH theo y√™u c·∫ßu
                ml_symbols = ['BTC/USDT', 'ETH/USDT']
                ml_timeframes = ['1h', '4h', '1d']  # Ch·ªâ train cho 3 timeframe ch√≠nh
                
                for symbol in ml_symbols:
                    for timeframe in ml_timeframes:
                        try:
                            logger.info(f"üîÑ Training ML models cho {symbol} ({timeframe})...")
                            
                            # Ki·ªÉm tra d·ªØ li·ªáu tr∆∞·ªõc khi train
                            data = load_or_fetch_historical_data(symbol, timeframe)
                            if data is None:
                                logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu cho {symbol} ({timeframe})")
                                continue
                            
                            logger.info(f"üìä D·ªØ li·ªáu {symbol} ({timeframe}): {len(data['close'])} candles")
                            
                            trained_models = train_ml_models(symbol, timeframe)
                            if trained_models:
                                logger.info(f"‚úÖ ƒê√£ train th√†nh c√¥ng {len(trained_models)} models cho {symbol} ({timeframe})")
                            else:
                                logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ train models cho {symbol} ({timeframe})")
                            
                            time.sleep(5)  # Ch·ªù 5 gi√¢y gi·ªØa c√°c l·∫ßn train
                        except Exception as e:
                            logger.error(f"‚ùå L·ªói khi train ML cho {symbol} ({timeframe}): {e}")
                            continue
                
                logger.info(f"‚è∞ Ch·ªù {ML_UPDATE_INTERVAL} gi√¢y ƒë·ªÉ train ML models ti·∫øp theo...")
                time.sleep(ML_UPDATE_INTERVAL)
                
            except Exception as e:
                logger.error(f"L·ªói trong ml_model_trainer_scheduler: {e}")
                time.sleep(3600)  # Ch·ªù 1 gi·ªù n·∫øu c√≥ l·ªói
    
    # Kh·ªüi ƒë·ªông thread train ML models ƒë·ªãnh k·ª≥
    ml_thread = threading.Thread(target=train_models_periodically, daemon=True)
    ml_thread.start()
    logger.info(f"ü§ñ ƒê√£ kh·ªüi ƒë·ªông ML Model Trainer Scheduler (train m·ªói {ML_UPDATE_INTERVAL//3600} gi·ªù)")

def calculate_entry_points(current_price, highs, lows, closes, rsi, bb_upper, bb_lower, ema50, pivot_points, support, resistance):
    """T√≠nh to√°n c√°c ƒëi·ªÉm entry h·ª£p l√Ω"""
    entry_points = {
        'immediate': current_price,
        'conservative': current_price,
        'aggressive': current_price,
        'stop_loss': current_price,
        'take_profit': current_price,
        'analysis': []
    }
    
    # Helper function ƒë·ªÉ l·∫•y gi√° tr·ªã cu·ªëi c√πng
    def get_last(series):
        return series.iloc[-1] if hasattr(series, 'iloc') else series[-1]
    
    # 1. Ph√¢n t√≠ch xu h∆∞·ªõng hi·ªán t·∫°i
    trend = 'neutral'
    if current_price > get_last(ema50):
        trend = 'bullish'
    else:
        trend = 'bearish'
    
    # 2. T√≠nh c√°c m·ª©c entry cho Long
    if trend == 'bullish':
        # Entry b·∫£o th·ªß (Conservative) - Ch·ªù pullback v·ªÅ h·ªó tr·ª£
        conservative_entry = min(support, get_last(bb_lower), pivot_points['s1'])
        entry_points['conservative'] = conservative_entry
        
        # Entry t√≠ch c·ª±c (Aggressive) - V√†o ngay khi c√≥ t√≠n hi·ªáu
        aggressive_entry = current_price * 0.995  # V√†o th·∫•p h∆°n gi√° hi·ªán t·∫°i 0.5%
        entry_points['aggressive'] = aggressive_entry
        
        # Stop Loss - D·ª±a tr√™n m·ª©c h·ªó tr·ª£ m·∫°nh (s2) ƒë·ªÉ t·∫°o R/R t·ªët h∆°n
        # S·ª≠ d·ª•ng s2 thay v√¨ s1 ƒë·ªÉ SL g·∫ßn entry h∆°n
        stop_loss = min(support * 0.998, get_last(bb_lower) * 0.999, pivot_points['s2'] * 0.999)
        entry_points['stop_loss'] = stop_loss
        
        # Take Profit - T·ª∑ l·ªá v·ªõi kho·∫£ng c√°ch SL ƒë·ªÉ t·∫°o R/R √≠t nh·∫•t 1:2
        sl_distance = current_price - stop_loss
        if sl_distance > 0:
            # TP = Entry + (SL_distance * 2.5) ƒë·ªÉ c√≥ R/R √≠t nh·∫•t 1:2.5
            take_profit = current_price + (sl_distance * 2.5)
        else:
            # Fallback n·∫øu kh√¥ng t√≠nh ƒë∆∞·ª£c SL distance
            atr = np.mean([highs[i] - lows[i] for i in range(-10, 0)])
            take_profit = current_price + (atr * 1.5)
        entry_points['take_profit'] = take_profit
        
        entry_points['analysis'].append(f"üìà XU H∆Ø·ªöNG TƒÇNG - ƒêi·ªÉm entry h·ª£p l√Ω:")
        entry_points['analysis'].append(f"  ‚Ä¢ Entry b·∫£o th·ªß: ${conservative_entry:.4f} (ch·ªù pullback)")
        entry_points['analysis'].append(f"  ‚Ä¢ Entry t√≠ch c·ª±c: ${aggressive_entry:.4f} (v√†o ngay)")
        entry_points['analysis'].append(f"  ‚Ä¢ Stop Loss: ${stop_loss:.4f}")
        entry_points['analysis'].append(f"  ‚Ä¢ Take Profit: ${take_profit:.4f}")
    
    # 3. T√≠nh c√°c m·ª©c entry cho Short
    elif trend == 'bearish':
        # Entry b·∫£o th·ªß - Ch·ªù bounce v·ªÅ kh√°ng c·ª±
        conservative_entry = max(resistance, get_last(bb_upper), pivot_points['r1'])
        entry_points['conservative'] = conservative_entry
        
        # Entry t√≠ch c·ª±c - V√†o ngay khi c√≥ t√≠n hi·ªáu
        aggressive_entry = current_price * 1.005  # V√†o cao h∆°n gi√° hi·ªán t·∫°i 0.5%
        entry_points['aggressive'] = aggressive_entry
        
        # Stop Loss - D·ª±a tr√™n m·ª©c kh√°ng c·ª± m·∫°nh (r2) ƒë·ªÉ t·∫°o R/R t·ªët h∆°n
        # S·ª≠ d·ª•ng r2 thay v√¨ r1 ƒë·ªÉ SL g·∫ßn entry h∆°n
        stop_loss = max(resistance * 1.002, get_last(bb_upper) * 1.001, pivot_points['r2'] * 1.001)
        entry_points['stop_loss'] = stop_loss
        
        # Take Profit - T·ª∑ l·ªá v·ªõi kho·∫£ng c√°ch SL ƒë·ªÉ t·∫°o R/R √≠t nh·∫•t 1:2
        sl_distance = stop_loss - current_price
        if sl_distance > 0:
            # TP = Entry - (SL_distance * 2.5) ƒë·ªÉ c√≥ R/R √≠t nh·∫•t 1:2.5
            take_profit = current_price - (sl_distance * 2.5)
        else:
            # Fallback n·∫øu kh√¥ng t√≠nh ƒë∆∞·ª£c SL distance
            atr = np.mean([highs[i] - lows[i] for i in range(-10, 0)])
            take_profit = current_price - (atr * 1.5)
        entry_points['take_profit'] = take_profit
        
        entry_points['analysis'].append(f"üìâ XU H∆Ø·ªöNG GI·∫¢M - ƒêi·ªÉm entry h·ª£p l√Ω:")
        entry_points['analysis'].append(f"  ‚Ä¢ Entry b·∫£o th·ªß: ${conservative_entry:.4f} (ch·ªù bounce)")
        entry_points['analysis'].append(f"  ‚Ä¢ Entry t√≠ch c·ª±c: ${aggressive_entry:.4f} (v√†o ngay)")
        entry_points['analysis'].append(f"  ‚Ä¢ Stop Loss: ${stop_loss:.4f}")
        entry_points['analysis'].append(f"  ‚Ä¢ Take Profit: ${take_profit:.4f}")
    
    # 4. Ph√¢n t√≠ch RSI ƒë·ªÉ t·ªëi ∆∞u entry
    if get_last(rsi) < 15:  # T·ª´ 20 -> 15
        entry_points['analysis'].append(f"  ‚Ä¢ RSI qu√° b√°n ({get_last(rsi):.1f}) ‚Üí ∆Øu ti√™n entry b·∫£o th·ªß")
    elif get_last(rsi) > 85:  # T·ª´ 80 -> 85
        entry_points['analysis'].append(f"  ‚Ä¢ RSI qu√° mua ({get_last(rsi):.1f}) ‚Üí ∆Øu ti√™n entry b·∫£o th·ªß")
    else:
        entry_points['analysis'].append(f"  ‚Ä¢ RSI trung t√≠nh ({get_last(rsi):.1f}) ‚Üí C√≥ th·ªÉ entry t√≠ch c·ª±c")
    
    # 5. Ph√¢n t√≠ch Bollinger Bands
    if current_price < get_last(bb_lower):
        entry_points['analysis'].append(f"  ‚Ä¢ Gi√° d∆∞·ªõi BB Lower ‚Üí C∆° h·ªôi entry t·ªët cho Long")
    elif current_price > get_last(bb_upper):
        entry_points['analysis'].append(f"  ‚Ä¢ Gi√° tr√™n BB Upper ‚Üí C∆° h·ªôi entry t·ªët cho Short")
    else:
        entry_points['analysis'].append(f"  ‚Ä¢ Gi√° trong BB ‚Üí Entry ·ªü gi·ªØa range")
    
    # 6. T√≠nh Risk/Reward Ratio
    if trend == 'bullish':
        risk = current_price - entry_points['stop_loss']
        reward = entry_points['take_profit'] - current_price
        rr_ratio = reward / risk if risk > 0 else 0
        entry_points['analysis'].append(f"  ‚Ä¢ Risk/Reward Ratio: 1:{rr_ratio:.2f}")
    elif trend == 'bearish':
        risk = entry_points['stop_loss'] - current_price
        reward = current_price - entry_points['take_profit']
        rr_ratio = reward / risk if risk > 0 else 0
        entry_points['analysis'].append(f"  ‚Ä¢ Risk/Reward Ratio: 1:{rr_ratio:.2f}")
    
    return entry_points

def detect_order_blocks(highs, lows, closes, volumes):
    """Ph√°t hi·ªán Order Blocks (SMC)"""
    order_blocks = []
    
    for i in range(2, len(closes) - 1):
        # Bullish Order Block (sau khi gi√° tƒÉng m·∫°nh)
        if (closes[i+1] > closes[i] * 1.02 and  # Gi√° tƒÉng > 2%
            volumes[i] > np.mean(volumes[max(0, i-10):i]) * 1.5):  # Volume cao
            
            # T√¨m v√πng order block (3-5 n·∫øn tr∆∞·ªõc ƒë√≥)
            block_start = max(0, i-5)
            block_high = max(highs[block_start:i+1])
            block_low = min(lows[block_start:i+1])
            
            order_blocks.append({
                'type': 'bullish',
                'start': block_start,
                'end': i,
                'high': block_high,
                'low': block_low,
                'strength': volumes[i] / np.mean(volumes[max(0, i-10):i])
            })
        
        # Bearish Order Block (sau khi gi√° gi·∫£m m·∫°nh)
        elif (closes[i+1] < closes[i] * 0.98 and  # Gi√° gi·∫£m > 2%
              volumes[i] > np.mean(volumes[max(0, i-10):i]) * 1.5):  # Volume cao
            
            # T√¨m v√πng order block (3-5 n·∫øn tr∆∞·ªõc ƒë√≥)
            block_start = max(0, i-5)
            block_high = max(highs[block_start:i+1])
            block_low = min(lows[block_start:i+1])
            
            order_blocks.append({
                'type': 'bearish',
                'start': block_start,
                'end': i,
                'high': block_high,
                'low': block_low,
                'strength': volumes[i] / np.mean(volumes[max(0, i-10):i])
            })
    
    return order_blocks

def detect_fair_value_gaps(highs, lows, closes):
    """Ph√°t hi·ªán Fair Value Gaps (FVG) - SMC"""
    fvgs = []
    
    for i in range(1, len(closes) - 1):
        # Bullish FVG (gap l√™n)
        if lows[i+1] > highs[i-1]:
            fvgs.append({
                'type': 'bullish',
                'position': i,
                'gap_low': highs[i-1],
                'gap_high': lows[i+1],
                'size': lows[i+1] - highs[i-1],
                'filled': False
            })
        
        # Bearish FVG (gap xu·ªëng)
        elif highs[i+1] < lows[i-1]:
            fvgs.append({
                'type': 'bearish',
                'position': i,
                'gap_low': highs[i+1],
                'gap_high': lows[i-1],
                'size': lows[i-1] - highs[i+1],
                'filled': False
            })
    
    return fvgs

def detect_liquidity_zones(highs, lows, closes, volumes):
    """Ph√°t hi·ªán Liquidity Zones (SMC)"""
    liquidity_zones = []
    
    # T√¨m c√°c swing highs v√† lows
    for i in range(2, len(closes) - 2):
        # Swing High (liquidity tr√™n)
        if (highs[i] > highs[i-1] and highs[i] > highs[i-2] and
            highs[i] > highs[i+1] and highs[i] > highs[i+2]):
            
            # Ki·ªÉm tra volume v√† wick
            wick_size = (highs[i] - max(closes[i], closes[i])) / (highs[i] - lows[i])
            if wick_size > 0.3:  # Wick d√†i
                liquidity_zones.append({
                    'type': 'liquidity_high',
                    'position': i,
                    'price': highs[i],
                    'strength': wick_size,
                    'volume': volumes[i]
                })
        
        # Swing Low (liquidity d∆∞·ªõi)
        elif (lows[i] < lows[i-1] and lows[i] < lows[i-2] and
              lows[i] < lows[i+1] and lows[i] < lows[i+2]):
            
            # Ki·ªÉm tra volume v√† wick
            wick_size = (min(closes[i], closes[i]) - lows[i]) / (highs[i] - lows[i])
            if wick_size > 0.3:  # Wick d√†i
                liquidity_zones.append({
                    'type': 'liquidity_low',
                    'position': i,
                    'price': lows[i],
                    'strength': wick_size,
                    'volume': volumes[i]
                })
    
    return liquidity_zones

def detect_mitigation_zones(highs, lows, closes):
    """Ph√°t hi·ªán Mitigation Zones (SMC) - v√πng ƒë·∫£o chi·ªÅu"""
    mitigation_zones = []
    
    for i in range(3, len(closes) - 3):
        # Bullish Mitigation (ƒë·∫£o chi·ªÅu tƒÉng)
        if (closes[i] > closes[i-1] and closes[i] > closes[i-2] and
            closes[i] > closes[i-3] and
            lows[i] < min(lows[i-3:i]) and  # T·∫°o ƒë√°y m·ªõi
            closes[i] > (highs[i-3] + lows[i-3]) / 2):  # ƒê√≥ng tr√™n midpoint
            
            mitigation_zones.append({
                'type': 'bullish_mitigation',
                'position': i,
                'price': closes[i],
                'strength': (closes[i] - lows[i]) / (highs[i] - lows[i])
            })
        
        # Bearish Mitigation (ƒë·∫£o chi·ªÅu gi·∫£m)
        elif (closes[i] < closes[i-1] and closes[i] < closes[i-2] and
              closes[i] < closes[i-3] and
              highs[i] > max(highs[i-3:i]) and  # T·∫°o ƒë·ªânh m·ªõi
              closes[i] < (highs[i-3] + lows[i-3]) / 2):  # ƒê√≥ng d∆∞·ªõi midpoint
            
            mitigation_zones.append({
                'type': 'bearish_mitigation',
                'position': i,
                'price': closes[i],
                'strength': (highs[i] - closes[i]) / (highs[i] - lows[i])
            })
    
    return mitigation_zones

def detect_price_action_patterns(highs, lows, closes, volumes):
    """Ph√°t hi·ªán c√°c m√¥ h√¨nh Price Action"""
    patterns = []
    
    # Inside Bar
    for i in range(1, len(closes)):
        if (highs[i] <= highs[i-1] and lows[i] >= lows[i-1]):
            patterns.append({
                'type': 'inside_bar',
                'position': i,
                'strength': (highs[i-1] - lows[i-1]) / (highs[i] - lows[i]) if highs[i] != lows[i] else 1
            })
    
    # Outside Bar
    for i in range(1, len(closes)):
        if (highs[i] > highs[i-1] and lows[i] < lows[i-1]):
            patterns.append({
                'type': 'outside_bar',
                'position': i,
                'strength': (highs[i] - lows[i]) / (highs[i-1] - lows[i-1]) if highs[i-1] != lows[i-1] else 1
            })
    
    # Pin Bar (Hammer/Shooting Star)
    for i in range(1, len(closes)):
        body_size = abs(closes[i] - closes[i-1])
        total_range = highs[i] - lows[i]
        
        if total_range > 0:
            body_ratio = body_size / total_range
            upper_wick = highs[i] - max(closes[i], closes[i-1])
            lower_wick = min(closes[i], closes[i-1]) - lows[i]
            
            # Pin Bar (body nh·ªè, wick d√†i)
            if body_ratio < 0.3:
                if upper_wick > body_size * 2 and lower_wick < body_size * 0.5:
                    patterns.append({
                        'type': 'pin_bar_bearish',
                        'position': i,
                        'strength': upper_wick / body_size
                    })
                elif lower_wick > body_size * 2 and upper_wick < body_size * 0.5:
                    patterns.append({
                        'type': 'pin_bar_bullish',
                        'position': i,
                        'strength': lower_wick / body_size
                    })
    
    # Engulfing Pattern
    for i in range(1, len(closes)):
        prev_body = abs(closes[i-1] - closes[i-2])
        curr_body = abs(closes[i] - closes[i-1])
        
        if curr_body > prev_body * 1.5:  # Body hi·ªán t·∫°i l·ªõn h∆°n 50%
            if closes[i] > closes[i-1] and closes[i-1] < closes[i-2]:  # Bullish Engulfing
                patterns.append({
                    'type': 'engulfing_bullish',
                    'position': i,
                    'strength': curr_body / prev_body
                })
            elif closes[i] < closes[i-1] and closes[i-1] > closes[i-2]:  # Bearish Engulfing
                patterns.append({
                    'type': 'engulfing_bearish',
                    'position': i,
                    'strength': curr_body / prev_body
                })
    
    return patterns

def analyze_smc_signals(current_price, order_blocks, fvgs, liquidity_zones, mitigation_zones):
    """Ph√¢n t√≠ch t√≠n hi·ªáu Smart Money Concepts"""
    smc_signals = {
        'order_block_signal': 'Hold',
        'fvg_signal': 'Hold',
        'liquidity_signal': 'Hold',
        'mitigation_signal': 'Hold',
        'analysis': []
    }
    
    # Ph√¢n t√≠ch Order Blocks
    nearby_bullish_ob = None
    nearby_bearish_ob = None
    
    for ob in order_blocks[-5:]:  # Ch·ªâ x√©t 5 order blocks g·∫ßn nh·∫•t
        if ob['type'] == 'bullish' and current_price >= ob['low'] and current_price <= ob['high']:
            nearby_bullish_ob = ob
        elif ob['type'] == 'bearish' and current_price >= ob['low'] and current_price <= ob['high']:
            nearby_bearish_ob = ob
    
    if nearby_bullish_ob:
        smc_signals['order_block_signal'] = 'Long'
        smc_signals['analysis'].append(f"üìà Bullish Order Block t·∫°i ${nearby_bullish_ob['low']:.4f} - ${nearby_bullish_ob['high']:.4f}")
    elif nearby_bearish_ob:
        smc_signals['order_block_signal'] = 'Short'
        smc_signals['analysis'].append(f"üìâ Bearish Order Block t·∫°i ${nearby_bearish_ob['low']:.4f} - ${nearby_bearish_ob['high']:.4f}")
    
    # Ph√¢n t√≠ch Fair Value Gaps
    nearby_fvg = None
    for fvg in fvgs[-3:]:  # Ch·ªâ x√©t 3 FVG g·∫ßn nh·∫•t
        if fvg['gap_low'] <= current_price <= fvg['gap_high']:
            nearby_fvg = fvg
            break
    
    if nearby_fvg:
        if nearby_fvg['type'] == 'bullish':
            smc_signals['fvg_signal'] = 'Long'
            smc_signals['analysis'].append(f"üìà Bullish FVG t·∫°i ${nearby_fvg['gap_low']:.4f} - ${nearby_fvg['gap_high']:.4f}")
        else:
            smc_signals['fvg_signal'] = 'Short'
            smc_signals['analysis'].append(f"üìâ Bearish FVG t·∫°i ${nearby_fvg['gap_low']:.4f} - ${nearby_fvg['gap_high']:.4f}")
    
    # Ph√¢n t√≠ch Liquidity Zones
    nearby_liquidity = None
    for lz in liquidity_zones[-3:]:  # Ch·ªâ x√©t 3 liquidity zones g·∫ßn nh·∫•t
        if abs(current_price - lz['price']) / lz['price'] < 0.02:  # Trong v√≤ng 2%
            nearby_liquidity = lz
            break
    
    if nearby_liquidity:
        if nearby_liquidity['type'] == 'liquidity_high':
            smc_signals['liquidity_signal'] = 'Short'  # C√≥ th·ªÉ b·ªã ƒë·∫£o chi·ªÅu gi·∫£m
            smc_signals['analysis'].append(f"üìâ Liquidity High t·∫°i ${nearby_liquidity['price']:.4f}")
        else:
            smc_signals['liquidity_signal'] = 'Long'  # C√≥ th·ªÉ b·ªã ƒë·∫£o chi·ªÅu tƒÉng
            smc_signals['analysis'].append(f"üìà Liquidity Low t·∫°i ${nearby_liquidity['price']:.4f}")
    
    # Ph√¢n t√≠ch Mitigation Zones
    recent_mitigation = None
    for mz in mitigation_zones[-2:]:  # Ch·ªâ x√©t 2 mitigation zones g·∫ßn nh·∫•t
        if abs(current_price - mz['price']) / mz['price'] < 0.05:  # Trong v√≤ng 5%
            recent_mitigation = mz
            break
    
    if recent_mitigation:
        if recent_mitigation['type'] == 'bullish_mitigation':
            smc_signals['mitigation_signal'] = 'Long'
            smc_signals['analysis'].append(f"üìà Bullish Mitigation t·∫°i ${recent_mitigation['price']:.4f}")
        else:
            smc_signals['mitigation_signal'] = 'Short'
            smc_signals['analysis'].append(f"üìâ Bearish Mitigation t·∫°i ${recent_mitigation['price']:.4f}")
    
    return smc_signals

def analyze_price_action_signals(current_price, price_action_patterns, highs, lows, closes):
    """Ph√¢n t√≠ch t√≠n hi·ªáu Price Action"""
    pa_signals = {
        'pattern_signal': 'Hold',
        'momentum_signal': 'Hold',
        'analysis': []
    }
    
    # Ph√¢n t√≠ch c√°c m√¥ h√¨nh Price Action g·∫ßn nh·∫•t
    recent_patterns = [p for p in price_action_patterns if p['position'] >= len(closes) - 5]
    
    bullish_patterns = 0
    bearish_patterns = 0
    
    for pattern in recent_patterns:
        if pattern['type'] in ['pin_bar_bullish', 'engulfing_bullish', 'outside_bar']:
            bullish_patterns += 1
        elif pattern['type'] in ['pin_bar_bearish', 'engulfing_bearish']:
            bearish_patterns += 1
    
    if bullish_patterns > bearish_patterns:
        pa_signals['pattern_signal'] = 'Long'
        pa_signals['analysis'].append(f"üìà {bullish_patterns} m√¥ h√¨nh Price Action bullish")
    elif bearish_patterns > bullish_patterns:
        pa_signals['pattern_signal'] = 'Short'
        pa_signals['analysis'].append(f"üìâ {bearish_patterns} m√¥ h√¨nh Price Action bearish")
    
    # Ph√¢n t√≠ch momentum
    recent_closes = closes[-5:]
    if len(recent_closes) >= 3:
        momentum = (recent_closes[-1] - recent_closes[-3]) / recent_closes[-3]
        
        if momentum > 0.02:  # TƒÉng > 2%
            pa_signals['momentum_signal'] = 'Long'
            pa_signals['analysis'].append(f"üìà Momentum tƒÉng {momentum:.2%}")
        elif momentum < -0.02:  # Gi·∫£m > 2%
            pa_signals['momentum_signal'] = 'Short'
            pa_signals['analysis'].append(f"üìâ Momentum gi·∫£m {momentum:.2%}")
    
    return pa_signals

def detect_divergence(price_data, indicator_data, lookback=14):
    """
    Ph√°t hi·ªán divergence gi·ªØa gi√° v√† ch·ªâ b√°o
    Returns: {'type': 'bullish/bearish/hidden_bullish/hidden_bearish', 'strength': 0-1}
    """
    if len(price_data) < lookback * 2:
        return None
    
    # Chuy·ªÉn ƒë·ªïi sang pandas Series n·∫øu c·∫ßn
    if not isinstance(price_data, pd.Series):
        price_data = pd.Series(price_data)
    if not isinstance(indicator_data, pd.Series):
        indicator_data = pd.Series(indicator_data)
    
    # T√¨m c√°c ƒë·ªânh v√† ƒë√°y trong gi√°
    price_peaks = []
    price_troughs = []
    
    for i in range(1, len(price_data) - 1):
        if price_data.iloc[i] > price_data.iloc[i-1] and price_data.iloc[i] > price_data.iloc[i+1]:
            price_peaks.append((i, price_data.iloc[i]))
        elif price_data.iloc[i] < price_data.iloc[i-1] and price_data.iloc[i] < price_data.iloc[i+1]:
            price_troughs.append((i, price_data.iloc[i]))
    
    # T√¨m c√°c ƒë·ªânh v√† ƒë√°y trong ch·ªâ b√°o
    indicator_peaks = []
    indicator_troughs = []
    
    for i in range(1, len(indicator_data) - 1):
        if indicator_data.iloc[i] > indicator_data.iloc[i-1] and indicator_data.iloc[i] > indicator_data.iloc[i+1]:
            indicator_peaks.append((i, indicator_data.iloc[i]))
        elif indicator_data.iloc[i] < indicator_data.iloc[i-1] and indicator_data.iloc[i] < indicator_data.iloc[i+1]:
            indicator_troughs.append((i, indicator_data.iloc[i]))
    
    # Ph√¢n t√≠ch divergence
    divergence_result = None
    
    # Regular Bullish Divergence: Gi√° t·∫°o ƒë√°y th·∫•p h∆°n, ch·ªâ b√°o t·∫°o ƒë√°y cao h∆°n
    if len(price_troughs) >= 2 and len(indicator_troughs) >= 2:
        recent_price_trough = price_troughs[-1]
        prev_price_trough = price_troughs[-2]
        recent_indicator_trough = indicator_troughs[-1]
        prev_indicator_trough = indicator_troughs[-2]
        
        if (recent_price_trough[1] < prev_price_trough[1] and 
            recent_indicator_trough[1] > prev_indicator_trough[1] and
            recent_price_trough[0] > prev_price_trough[0] and
            recent_indicator_trough[0] > prev_indicator_trough[0]):
            
            strength = min(1.0, abs(recent_price_trough[1] - prev_price_trough[1]) / prev_price_trough[1])
            divergence_result = {'type': 'bullish', 'strength': strength}
    
    # Regular Bearish Divergence: Gi√° t·∫°o ƒë·ªânh cao h∆°n, ch·ªâ b√°o t·∫°o ƒë·ªânh th·∫•p h∆°n
    elif len(price_peaks) >= 2 and len(indicator_peaks) >= 2:
        recent_price_peak = price_peaks[-1]
        prev_price_peak = price_peaks[-2]
        recent_indicator_peak = indicator_peaks[-1]
        prev_indicator_peak = indicator_peaks[-2]
        
        if (recent_price_peak[1] > prev_price_peak[1] and 
            recent_indicator_peak[1] < prev_indicator_peak[1] and
            recent_price_peak[0] > prev_price_peak[0] and
            recent_indicator_peak[0] > prev_indicator_peak[0]):
            
            strength = min(1.0, abs(recent_price_peak[1] - prev_price_peak[1]) / prev_price_peak[1])
            divergence_result = {'type': 'bearish', 'strength': strength}
    
    # Hidden Bullish Divergence: Gi√° t·∫°o ƒë√°y cao h∆°n, ch·ªâ b√°o t·∫°o ƒë√°y th·∫•p h∆°n
    elif len(price_troughs) >= 2 and len(indicator_troughs) >= 2:
        recent_price_trough = price_troughs[-1]
        prev_price_trough = price_troughs[-2]
        recent_indicator_trough = indicator_troughs[-1]
        prev_indicator_trough = indicator_troughs[-2]
        
        if (recent_price_trough[1] > prev_price_trough[1] and 
            recent_indicator_trough[1] < prev_indicator_trough[1] and
            recent_price_trough[0] > prev_price_trough[0] and
            recent_indicator_trough[0] > prev_indicator_trough[0]):
            
            strength = min(1.0, abs(recent_price_trough[1] - prev_price_trough[1]) / prev_price_trough[1])
            divergence_result = {'type': 'hidden_bullish', 'strength': strength}
    
    # Hidden Bearish Divergence: Gi√° t·∫°o ƒë·ªânh th·∫•p h∆°n, ch·ªâ b√°o t·∫°o ƒë·ªânh cao h∆°n
    elif len(price_peaks) >= 2 and len(indicator_peaks) >= 2:
        recent_price_peak = price_peaks[-1]
        prev_price_peak = price_peaks[-2]
        recent_indicator_peak = indicator_peaks[-1]
        prev_indicator_peak = indicator_peaks[-2]
        
        if (recent_price_peak[1] < prev_price_peak[1] and 
            recent_indicator_peak[1] > prev_indicator_peak[1] and
            recent_price_peak[0] > prev_price_peak[0] and
            recent_indicator_peak[0] > prev_indicator_peak[0]):
            
            strength = min(1.0, abs(recent_price_peak[1] - prev_price_peak[1]) / prev_price_peak[1])
            divergence_result = {'type': 'hidden_bearish', 'strength': strength}
    
    return divergence_result

def analyze_rsi_divergence(close_prices, rsi_values):
    """Ph√¢n t√≠ch RSI divergence"""
    if len(close_prices) < 20 or len(rsi_values) < 20:
        return None
    
    # L·ªçc d·ªØ li·ªáu kh√¥ng null
    valid_indices = []
    for i in range(len(close_prices)):
        if not np.isnan(close_prices[i]) and not np.isnan(rsi_values[i]):
            valid_indices.append(i)
    
    if len(valid_indices) < 20:
        return None
    
    close_clean = [close_prices[i] for i in valid_indices]
    rsi_clean = [rsi_values[i] for i in valid_indices]
    
    divergence = detect_divergence(close_clean, rsi_clean, lookback=14)
    
    if divergence:
        # Th√™m th√¥ng tin chi ti·∫øt
        divergence['indicator'] = 'RSI'
        divergence['description'] = get_divergence_description(divergence['type'], 'RSI')
        divergence['signal'] = get_divergence_signal(divergence['type'])
    
    return divergence

def analyze_macd_divergence(close_prices, macd_values):
    """Ph√¢n t√≠ch MACD divergence"""
    if len(close_prices) < 20 or len(macd_values) < 20:
        return None
    
    # L·ªçc d·ªØ li·ªáu kh√¥ng null
    valid_indices = []
    for i in range(len(close_prices)):
        if not np.isnan(close_prices[i]) and not np.isnan(macd_values[i]):
            valid_indices.append(i)
    
    if len(valid_indices) < 20:
        return None
    
    close_clean = [close_prices[i] for i in valid_indices]
    macd_clean = [macd_values[i] for i in valid_indices]
    
    divergence = detect_divergence(close_clean, macd_clean, lookback=14)
    
    if divergence:
        # Th√™m th√¥ng tin chi ti·∫øt
        divergence['indicator'] = 'MACD'
        divergence['description'] = get_divergence_description(divergence['type'], 'MACD')
        divergence['signal'] = get_divergence_signal(divergence['type'])
    
    return divergence

def analyze_price_volume_divergence(close_prices, volume_data):
    """Ph√¢n t√≠ch divergence gi·ªØa gi√° v√† kh·ªëi l∆∞·ª£ng"""
    if len(close_prices) < 20 or len(volume_data) < 20:
        return None
    
    # T√≠nh to√°n volume moving average ƒë·ªÉ so s√°nh
    volume_ma = ta.trend.sma_indicator(volume_data, window=10)
    
    # L·ªçc d·ªØ li·ªáu kh√¥ng null
    valid_indices = []
    for i in range(len(close_prices)):
        if not np.isnan(close_prices[i]) and not np.isnan(volume_ma[i]):
            valid_indices.append(i)
    
    if len(valid_indices) < 20:
        return None
    
    close_clean = [close_prices[i] for i in valid_indices]
    volume_ma_clean = [volume_ma[i] for i in valid_indices]
    
    divergence = detect_divergence(close_clean, volume_ma_clean, lookback=14)
    
    if divergence:
        # Th√™m th√¥ng tin chi ti·∫øt
        divergence['indicator'] = 'Volume'
        divergence['description'] = get_divergence_description(divergence['type'], 'Volume')
        divergence['signal'] = get_divergence_signal(divergence['type'])
    
    return divergence

def get_divergence_description(divergence_type, indicator):
    """T·∫°o m√¥ t·∫£ chi ti·∫øt cho divergence"""
    descriptions = {
        'bullish': {
            'RSI': 'RSI t·∫°o ƒë√°y cao h∆°n trong khi gi√° t·∫°o ƒë√°y th·∫•p h∆°n ‚Üí T√≠n hi·ªáu ƒë·∫£o chi·ªÅu tƒÉng m·∫°nh',
            'MACD': 'MACD t·∫°o ƒë√°y cao h∆°n trong khi gi√° t·∫°o ƒë√°y th·∫•p h∆°n ‚Üí T√≠n hi·ªáu ƒë·∫£o chi·ªÅu tƒÉng m·∫°nh',
            'Volume': 'Kh·ªëi l∆∞·ª£ng tƒÉng trong khi gi√° gi·∫£m ‚Üí T√≠n hi·ªáu t√≠ch l≈©y, s·∫µn s√†ng ƒë·∫£o chi·ªÅu tƒÉng'
        },
        'bearish': {
            'RSI': 'RSI t·∫°o ƒë·ªânh th·∫•p h∆°n trong khi gi√° t·∫°o ƒë·ªânh cao h∆°n ‚Üí T√≠n hi·ªáu ƒë·∫£o chi·ªÅu gi·∫£m m·∫°nh',
            'MACD': 'MACD t·∫°o ƒë·ªânh th·∫•p h∆°n trong khi gi√° t·∫°o ƒë·ªânh cao h∆°n ‚Üí T√≠n hi·ªáu ƒë·∫£o chi·ªÅu gi·∫£m m·∫°nh',
            'Volume': 'Kh·ªëi l∆∞·ª£ng gi·∫£m trong khi gi√° tƒÉng ‚Üí T√≠n hi·ªáu ph√¢n ph·ªëi, s·∫µn s√†ng ƒë·∫£o chi·ªÅu gi·∫£m'
        },
        'hidden_bullish': {
            'RSI': 'RSI t·∫°o ƒë√°y th·∫•p h∆°n trong khi gi√° t·∫°o ƒë√°y cao h∆°n ‚Üí Xu h∆∞·ªõng tƒÉng ti·∫øp di·ªÖn',
            'MACD': 'MACD t·∫°o ƒë√°y th·∫•p h∆°n trong khi gi√° t·∫°o ƒë√°y cao h∆°n ‚Üí Xu h∆∞·ªõng tƒÉng ti·∫øp di·ªÖn',
            'Volume': 'Kh·ªëi l∆∞·ª£ng gi·∫£m trong khi gi√° tƒÉng ‚Üí Xu h∆∞·ªõng tƒÉng ti·∫øp di·ªÖn'
        },
        'hidden_bearish': {
            'RSI': 'RSI t·∫°o ƒë·ªânh cao h∆°n trong khi gi√° t·∫°o ƒë·ªânh th·∫•p h∆°n ‚Üí Xu h∆∞·ªõng gi·∫£m ti·∫øp di·ªÖn',
            'MACD': 'MACD t·∫°o ƒë·ªânh cao h∆°n trong khi gi√° t·∫°o ƒë·ªânh th·∫•p h∆°n ‚Üí Xu h∆∞·ªõng gi·∫£m ti·∫øp di·ªÖn',
            'Volume': 'Kh·ªëi l∆∞·ª£ng tƒÉng trong khi gi√° gi·∫£m ‚Üí Xu h∆∞·ªõng gi·∫£m ti·∫øp di·ªÖn'
        }
    }
    
    return descriptions.get(divergence_type, {}).get(indicator, f'{divergence_type} divergence detected')

def get_divergence_signal(divergence_type):
    """Chuy·ªÉn ƒë·ªïi lo·∫°i divergence th√†nh t√≠n hi·ªáu giao d·ªãch"""
    signal_map = {
        'bullish': 'Long',
        'hidden_bullish': 'Long',
        'bearish': 'Short',
        'hidden_bearish': 'Short'
    }
    return signal_map.get(divergence_type, 'Hold')

def analyze_all_divergences(close_prices, rsi_values, macd_values, volume_data):
    """Ph√¢n t√≠ch t·∫•t c·∫£ c√°c lo·∫°i divergence"""
    divergences = []
    
    # RSI Divergence
    rsi_div = analyze_rsi_divergence(close_prices, rsi_values)
    if rsi_div:
        divergences.append(rsi_div)
    
    # MACD Divergence
    macd_div = analyze_macd_divergence(close_prices, macd_values)
    if macd_div:
        divergences.append(macd_div)
    
    # Price-Volume Divergence
    volume_div = analyze_price_volume_divergence(close_prices, volume_data)
    if volume_div:
        divergences.append(volume_div)
    
    return divergences

def calculate_divergence_consensus(divergences):
    """T√≠nh to√°n consensus t·ª´ c√°c divergence"""
    if not divergences:
        return {'signal': 'Hold', 'strength': 0, 'count': 0}
    
    long_signals = [d for d in divergences if d['signal'] == 'Long']
    short_signals = [d for d in divergences if d['signal'] == 'Short']
    
    if len(long_signals) > len(short_signals):
        avg_strength = sum(d['strength'] for d in long_signals) / len(long_signals)
        return {
            'signal': 'Long',
            'strength': avg_strength,
            'count': len(long_signals),
            'divergences': long_signals
        }
    elif len(short_signals) > len(long_signals):
        avg_strength = sum(d['strength'] for d in short_signals) / len(short_signals)
        return {
            'signal': 'Short',
            'strength': avg_strength,
            'count': len(short_signals),
            'divergences': short_signals
        }
    else:
        # N·∫øu s·ªë l∆∞·ª£ng b·∫±ng nhau, ch·ªçn theo strength cao h∆°n
        max_long_strength = max([d['strength'] for d in long_signals]) if long_signals else 0
        max_short_strength = max([d['strength'] for d in short_signals]) if short_signals else 0
        
        if max_long_strength > max_short_strength:
            return {
                'signal': 'Long',
                'strength': max_long_strength,
                'count': len(long_signals),
                'divergences': long_signals
            }
        elif max_short_strength > max_long_strength:
            return {
                'signal': 'Short',
                'strength': max_short_strength,
                'count': len(short_signals),
                'divergences': short_signals
            }
        else:
            return {'signal': 'Hold', 'strength': 0, 'count': 0}

def fetch_historical_data_for_ml(symbol, timeframe, limit=None):
    """L·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ cho ML training t·ª´ Binance API"""
    try:
        if limit is None:
            limit = ML_HISTORICAL_CANDLES
            
        logger.info(f"üìä ƒêang l·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol} ({timeframe}) - {limit} candles...")
        
        # L·∫•y d·ªØ li·ªáu t·ª´ Binance
        ohlcv = exchange.fetch_ohlcv(symbol, timeframe, limit=limit)
        
        if not ohlcv or len(ohlcv) < ML_MIN_SAMPLES:
            logger.warning(f"‚ö†Ô∏è Kh√¥ng ƒë·ªß d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol} ({timeframe}): {len(ohlcv) if ohlcv else 0} candles")
            return None
        
        # Chuy·ªÉn ƒë·ªïi th√†nh DataFrame
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)
        
        # L∆∞u d·ªØ li·ªáu g·ªëc (thay th·∫ø k√Ω t·ª± / b·∫±ng _)
        safe_symbol = symbol.replace('/', '_')
        data_file = os.path.join(ML_DATA_DIR, f"{safe_symbol}_{timeframe}_historical.csv")
        df.to_csv(data_file)
        
        logger.info(f"‚úÖ ƒê√£ l·∫•y v√† l∆∞u {len(df)} candles l·ªãch s·ª≠ cho {symbol} ({timeframe})")
        
        return {
            'open': df['open'].values,
            'high': df['high'].values,
            'low': df['low'].values,
            'close': df['close'].values,
            'volume': df['volume'].values,
            'timestamp': df.index.values
        }
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi l·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol} ({timeframe}): {e}")
        return None

def load_or_fetch_historical_data(symbol, timeframe):
    """Load d·ªØ li·ªáu l·ªãch s·ª≠ t·ª´ file ho·∫∑c fetch t·ª´ API n·∫øu ch∆∞a c√≥"""
    try:
        safe_symbol = symbol.replace('/', '_')
        data_file = os.path.join(ML_DATA_DIR, f"{safe_symbol}_{timeframe}_historical.csv")
        
        # Ki·ªÉm tra xem file c√≥ t·ªìn t·∫°i v√† c√≤n m·ªõi kh√¥ng (trong v√≤ng 24h)
        if os.path.exists(data_file):
            file_time = os.path.getmtime(data_file)
            current_time = time.time()
            
            # N·∫øu file c√≤n m·ªõi (trong v√≤ng 24h), load t·ª´ file
            if current_time - file_time < 86400:  # 24 gi·ªù
                logger.info(f"üìÇ Loading d·ªØ li·ªáu l·ªãch s·ª≠ t·ª´ file cho {symbol} ({timeframe})...")
                df = pd.read_csv(data_file, index_col='timestamp', parse_dates=True)
                
                return {
                    'open': df['open'].values,
                    'high': df['high'].values,
                    'low': df['low'].values,
                    'close': df['close'].values,
                    'volume': df['volume'].values,
                    'timestamp': df.index.values
                }
        
        # N·∫øu kh√¥ng c√≥ file ho·∫∑c file c≈©, fetch t·ª´ API
        return fetch_historical_data_for_ml(symbol, timeframe)
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi load/fetch d·ªØ li·ªáu l·ªãch s·ª≠ cho {symbol} ({timeframe}): {e}")
        return None

def display_ml_features_info():
    """Hi·ªÉn th·ªã th√¥ng tin v·ªÅ c√°c features ML"""
    features_info = {
        'Technical Indicators (12)': [
            'RSI - Relative Strength Index',
            'MACD - Moving Average Convergence Divergence',
            'MACD Signal - MACD Signal Line',
            'BB Position - Bollinger Bands Position',
            'BB Width - Bollinger Bands Width',
            'EMA Ratio 20/50 - Exponential Moving Average Ratio',
            'MA Ratio 20/50 - Simple Moving Average Ratio',
            'Stoch K - Stochastic Oscillator %K',
            'Stoch D - Stochastic Oscillator %D',
            'ADX - Average Directional Index',
            'ATR - Average True Range',
            'OBV - On Balance Volume'
        ],
        'Price Features (8)': [
            'Price Change - Percentage Change',
            'High/Low Ratio - High to Low Price Ratio',
            'Close/Open Ratio - Close to Open Price Ratio',
            'RSI Oversold - RSI Below 30',
            'RSI Overbought - RSI Above 70',
            'MACD Cross - MACD Above Signal',
            'MACD Histogram - MACD - Signal',
            'Momentum - 5-period Price Change',
            'Rate of Change - 5-period Percentage Change',
            'Volatility Ratio - Standard Deviation Ratio'
        ],
        'Volume Features (3)': [
            'Volume Ratio - Current Volume to MA',
            'Volume Z-Score - Volume Standardization',
            'Volume Price Trend - Volume * Price Change'
        ],
        'Support/Resistance (2)': [
            'Support Distance - Distance to Support Level',
            'Resistance Distance - Distance to Resistance Level'
        ],
        'Market Structure (2)': [
            'Trend Strength - Higher Highs vs Lower Lows',
            'Price Acceleration - Rate of Price Change'
        ],
        'Price Patterns (2)': [
            'Hammer - Hammer Candlestick Pattern',
            'Doji - Doji Candlestick Pattern'
        ]
    }
    
    print("\nü§ñ MACHINE LEARNING FEATURES (35+ Features)")
    print("=" * 50)
    
    total_features = 0
    for category, features in features_info.items():
        print(f"\nüìä {category}:")
        for feature in features:
            print(f"   ‚Ä¢ {feature}")
        total_features += len(features)
    
    print(f"\nüìà T·ªïng c·ªông: {total_features} features")
    print("üéØ Target: Next period price direction (1 = Up, 0 = Down)")
    print("üìä Training Data: 5000 historical candles from Binance API")
    print("ü§ñ Models: Random Forest, XGBoost, LightGBM, Gradient Boosting, Logistic Regression, SVM")
    print("üîÑ Auto-training: Every 24 hours")
    print("üíæ Data Storage: Historical data cached locally")

def get_ml_training_status():
    """Ki·ªÉm tra tr·∫°ng th√°i training ML models"""
    try:
        ensure_ml_directories()
        
        status = {
            'models_trained': [],
            'models_missing': [],
            'last_training': None,
            'data_files': []
        }
        
        # Ki·ªÉm tra models ƒë√£ train
        for symbol in ['BTC/USDT', 'ETH/USDT']:
            for timeframe in ML_TIMEFRAMES:
                model_files = []
                for model_type in ['random_forest', 'xgboost', 'lightgbm', 'gradient_boosting', 'logistic_regression', 'svm']:
                    safe_symbol = symbol.replace('/', '_')
                    model_file = os.path.join(ML_MODELS_DIR, f"{safe_symbol}_{timeframe}_{model_type}.joblib")
                    if os.path.exists(model_file):
                        model_files.append(model_type)
                
                if model_files:
                    status['models_trained'].append(f"{symbol} ({timeframe}): {len(model_files)} models")
                else:
                    status['models_missing'].append(f"{symbol} ({timeframe})")
        
        # Ki·ªÉm tra data files
        data_files = [f for f in os.listdir(ML_DATA_DIR) if f.endswith('_historical.csv')]
        status['data_files'] = data_files
        
        return status
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi ki·ªÉm tra tr·∫°ng th√°i ML: {e}")
        return None

def main():
    logger.info("B·∫Øt ƒë·∫ßu ph√¢n t√≠ch xu h∆∞·ªõng ng·∫Øn h·∫°n v·ªõi ML v√† Convergence Analysis...")
    
    # ƒê·∫£m b·∫£o c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt
    ensure_prediction_data_dir()
    ensure_ml_directories()
    
    # Hi·ªÉn th·ªã th√¥ng tin ML features
    display_ml_features_info()
    
    # Ki·ªÉm tra tr·∫°ng th√°i ML training
    ml_status = get_ml_training_status()
    if ml_status:
        print(f"\nüìä ML Training Status:")
        print(f"‚úÖ Models trained: {len(ml_status['models_trained'])}")
        print(f"‚ùå Models missing: {len(ml_status['models_missing'])}")
        print(f"üìÅ Data files: {len(ml_status['data_files'])}")
    
    # Train ML models m·ªôt l·∫ßn (kh√¥ng c√≥ scheduler)
    logger.info("ü§ñ B·∫Øt ƒë·∫ßu train ML models...")
    symbols_to_train = ['BTC/USDT', 'ETH/USDT']
    timeframes_to_train = ML_TIMEFRAMES
    
    for symbol in symbols_to_train:
        for timeframe in timeframes_to_train:
            logger.info(f"üîÑ Training ML models cho {symbol} ({timeframe})...")
            try:
                train_ml_models(symbol, timeframe)
                logger.info(f"‚úÖ ƒê√£ train th√†nh c√¥ng cho {symbol} ({timeframe})")
            except Exception as e:
                logger.error(f"‚ùå L·ªói train {symbol} ({timeframe}): {e}")
    
    # Ph√¢n t√≠ch c√°c symbols
    symbols = get_usdt_symbols()
    logger.info(f"ƒê√£ ch·ªçn {len(symbols)} t√†i s·∫£n: {symbols}")
    
    results = []
    for symbol in symbols:
        result = analyze_coin(symbol)
        if result:
            results.append(result)
            logger.info(f"‚úÖ ƒê√£ ph√¢n t√≠ch {symbol} th√†nh c√¥ng")

    # Hi·ªÉn th·ªã th·ªëng k√™ ƒë·ªô ch√≠nh x√°c n·∫øu c√≥
    accuracy_data = get_prediction_accuracy_data()
    if accuracy_data and accuracy_data.get('overall', {}).get('total_predictions', 0) > 0:
        overall = accuracy_data['overall']
        logger.info(f"üìà Th·ªëng k√™ ƒë·ªô ch√≠nh x√°c: {overall['accuracy']:.1%} ({overall['accurate_predictions']}/{overall['total_predictions']})")
    
    # G·ª≠i b√°o c√°o Telegram
    logger.info(f"üîç DEBUG: C√≥ {len(results)} k·∫øt qu·∫£ ƒë·ªÉ g·ª≠i")
    if results:
        report = format_analysis_report(results)
        logger.info(f"üîç DEBUG: Report length = {len(report)} characters")
        logger.info(f"üîç DEBUG: Report preview = {report[:200]}...")
        success = send_telegram_message(report)
        if success:
            logger.info("üì± ƒê√£ g·ª≠i b√°o c√°o Telegram th√†nh c√¥ng!")
        else:
            logger.error("‚ùå L·ªói g·ª≠i b√°o c√°o Telegram")
    else:
        logger.info("üìä Kh√¥ng c√≥ k·∫øt qu·∫£ ph√¢n t√≠ch ƒë·ªÉ g·ª≠i")
    
    logger.info("üèÅ Ho√†n th√†nh ph√¢n t√≠ch!")

if __name__ == "__main__":
    main()
