# Incremental Data Update System

## Tá»•ng quan

Há»‡ thá»‘ng incremental data update cho phÃ©p bot cáº­p nháº­t dá»¯ liá»‡u ML má»™t cÃ¡ch thÃ´ng minh, chá»‰ táº£i dá»¯ liá»‡u má»›i thay vÃ¬ táº£i láº¡i toÃ n bá»™ dá»¯ liá»‡u má»—i láº§n cháº¡y. Äiá»u nÃ y giÃºp:

- **Tiáº¿t kiá»‡m thá»i gian**: Chá»‰ táº£i dá»¯ liá»‡u má»›i tá»« láº§n cháº¡y cuá»‘i
- **Tiáº¿t kiá»‡m bÄƒng thÃ´ng**: Giáº£m lÆ°á»£ng dá»¯ liá»‡u cáº§n táº£i tá»« API
- **TÄƒng hiá»‡u suáº¥t**: Dá»¯ liá»‡u Ä‘Æ°á»£c cache locally vÃ  merge thÃ´ng minh
- **Giá»¯ kÃ­ch thÆ°á»›c repository há»£p lÃ½**: Tá»± Ä‘á»™ng dá»n dáº¹p dá»¯ liá»‡u cÅ©

## CÃ¡c tÃ­nh nÄƒng chÃ­nh

### 1. Incremental Data Loading
- **`load_and_update_historical_data()`**: Load dá»¯ liá»‡u hiá»‡n cÃ³ vÃ  merge vá»›i dá»¯ liá»‡u má»›i
- **`fetch_incremental_data()`**: Láº¥y dá»¯ liá»‡u má»›i tá»« timestamp cuá»‘i cÃ¹ng
- **`merge_historical_data()`**: Merge dá»¯ liá»‡u cÅ© vÃ  má»›i, loáº¡i bá» duplicates

### 2. Data Freshness Checking
- **`check_data_freshness()`**: Kiá»ƒm tra Ä‘á»™ má»›i cá»§a dá»¯ liá»‡u (máº·c Ä‘á»‹nh 24h)
- **`get_data_statistics()`**: Láº¥y thá»‘ng kÃª chi tiáº¿t vá» dá»¯ liá»‡u
- **`display_data_update_summary()`**: Hiá»ƒn thá»‹ tÃ³m táº¯t tÃ¬nh tráº¡ng dá»¯ liá»‡u

### 3. Smart Data Management
- **`cleanup_old_data_files()`**: Tá»± Ä‘á»™ng dá»n dáº¹p file cÅ© (giá»¯ tá»‘i Ä‘a 10,000 candles/file)
- **`get_latest_timestamp_from_data()`**: Láº¥y timestamp má»›i nháº¥t tá»« dá»¯ liá»‡u

## CÃ¡ch hoáº¡t Ä‘á»™ng

### Láº§n cháº¡y Ä‘áº§u tiÃªn
```python
# Force full update - táº£i toÃ n bá»™ dá»¯ liá»‡u
data = load_and_update_historical_data(symbol, timeframe, force_full_update=True)
```

### CÃ¡c láº§n cháº¡y tiáº¿p theo
```python
# Incremental update - chá»‰ táº£i dá»¯ liá»‡u má»›i
data = load_and_update_historical_data(symbol, timeframe, force_full_update=False)
```

### Logic merge dá»¯ liá»‡u
1. Load dá»¯ liá»‡u hiá»‡n cÃ³ tá»« file CSV
2. Láº¥y timestamp má»›i nháº¥t
3. Fetch dá»¯ liá»‡u má»›i tá»« API tá»« timestamp Ä‘Ã³
4. Merge vÃ  loáº¡i bá» duplicates
5. LÆ°u láº¡i file Ä‘Ã£ merge

## Cáº¥u hÃ¬nh

### Thá»i gian cache dá»¯ liá»‡u
```python
# Trong script.py
max_age_hours = 24  # Dá»¯ liá»‡u Ä‘Æ°á»£c coi lÃ  "má»›i" trong 24h
```

### Giá»›i háº¡n kÃ­ch thÆ°á»›c file
```python
max_candles_per_file = 10000  # Tá»‘i Ä‘a 10,000 candles/file
ML_HISTORICAL_CANDLES = 5000  # Sá»‘ candles máº·c Ä‘á»‹nh cho ML training
```

## Monitoring vÃ  Logging

### Thá»‘ng kÃª dá»¯ liá»‡u
```bash
ğŸ“Š TÃ“M Táº®T Cáº¬P NHáº¬T Dá»® LIá»†U:
==================================================
âœ… BTC/USDT (1h): 5000 candles, 2.34MB
   ğŸ“… 2024-01-01 00:00 â†’ 2024-01-15 12:00
   ğŸ•’ Dá»¯ liá»‡u má»›i (2.5 giá»)
âœ… ETH/USDT (4h): 3000 candles, 1.45MB
   ğŸ“… 2024-01-01 00:00 â†’ 2024-01-15 12:00
   ğŸ•’ Dá»¯ liá»‡u má»›i (1.2 giá»)
==================================================
ğŸ“ˆ Tá»•ng cá»™ng: 14 files, 35,000 candles, 15.67MB
```

### Log messages
```
ğŸ“ Loaded 5000 existing candles for BTC/USDT (1h)
ğŸ”„ Merged data: 5000 existing + 24 new = 5024 total
ğŸ’¾ Saved 5024 candles to ml_data/BTC_USDT_1h_historical.csv
```

## Testing

Cháº¡y test script Ä‘á»ƒ kiá»ƒm tra tÃ­nh nÄƒng:
```bash
python test_incremental_data.py
```

Test script sáº½ kiá»ƒm tra:
- Force full update
- Incremental update
- Data consistency
- File cleanup
- Statistics generation

## Lá»£i Ã­ch

### So vá»›i há»‡ thá»‘ng cÅ©
| TiÃªu chÃ­ | Há»‡ thá»‘ng cÅ© | Há»‡ thá»‘ng má»›i |
|----------|-------------|--------------|
| Thá»i gian táº£i dá»¯ liá»‡u | 30-60 giÃ¢y | 5-15 giÃ¢y |
| LÆ°á»£ng dá»¯ liá»‡u táº£i | 5000 candles | 24-100 candles |
| BÄƒng thÃ´ng sá»­ dá»¥ng | Cao | Tháº¥p |
| Hiá»‡u suáº¥t | Cháº­m | Nhanh |
| Äá»™ tin cáº­y | Tháº¥p (phá»¥ thuá»™c API) | Cao (cÃ³ cache) |

### Tá»‘i Æ°u hÃ³a cho GitHub Actions
- **Giáº£m thá»i gian cháº¡y**: Tá»« 5-10 phÃºt xuá»‘ng 2-3 phÃºt
- **Giáº£m lá»—i API**: Ãt request hÆ¡n = Ã­t lá»—i hÆ¡n
- **Tiáº¿t kiá»‡m quota**: Sá»­ dá»¥ng Ã­t API calls hÆ¡n
- **Dá»¯ liá»‡u liÃªn tá»¥c**: KhÃ´ng bá»‹ máº¥t dá»¯ liá»‡u giá»¯a cÃ¡c láº§n cháº¡y

## Troubleshooting

### Dá»¯ liá»‡u khÃ´ng Ä‘Æ°á»£c cáº­p nháº­t
```python
# Force full update
data = load_and_update_historical_data(symbol, timeframe, force_full_update=True)
```

### File dá»¯ liá»‡u bá»‹ corrupt
```python
# XÃ³a file vÃ  táº£i láº¡i
import os
os.remove(f"ml_data/{symbol}_{timeframe}_historical.csv")
data = load_and_update_historical_data(symbol, timeframe, force_full_update=True)
```

### Kiá»ƒm tra tÃ¬nh tráº¡ng dá»¯ liá»‡u
```python
stats = get_data_statistics(symbol, timeframe)
is_fresh, msg = check_data_freshness(symbol, timeframe)
print(f"Status: {msg}")
```

## TÆ°Æ¡ng lai

### Cáº£i tiáº¿n cÃ³ thá»ƒ thÃªm
- **Compression**: NÃ©n dá»¯ liá»‡u Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c file
- **Backup**: Tá»± Ä‘á»™ng backup dá»¯ liá»‡u quan trá»ng
- **Validation**: Kiá»ƒm tra tÃ­nh há»£p lá»‡ cá»§a dá»¯ liá»‡u
- **Parallel processing**: Táº£i dá»¯ liá»‡u song song cho nhiá»u symbols
- **Cloud storage**: LÆ°u trá»¯ dá»¯ liá»‡u trÃªn cloud thay vÃ¬ local

### Monitoring nÃ¢ng cao
- **Data quality metrics**: Äo lÆ°á»ng cháº¥t lÆ°á»£ng dá»¯ liá»‡u
- **Performance metrics**: Theo dÃµi hiá»‡u suáº¥t táº£i dá»¯ liá»‡u
- **Alert system**: Cáº£nh bÃ¡o khi cÃ³ váº¥n Ä‘á» vá»›i dá»¯ liá»‡u
